%!TEX root = main.tex
\section{Additional Examples}
\label{sec:additional}
\subsection{Random Effects versus Fixed Effects Example}
\label{sec:REvsFE}
In this section we consider a simple example in which the GFIC is used to choose between and average over alternative assumptions about individual heterogeneity: Random Effects versus Fixed Effects.
For simplicity we consider the homoskedastic case and assume that any strictly exogenous regressors, including a constant term, have been ``projected out'' so we may treat all random variables as mean zero.
To avoid triple subscripts in the notation, we further suppress the dependence of random variables on the cross-section dimension $n$ except within statements of theorems.
Suppose that
\begin{eqnarray}
  y_{it} &=& \beta x_{it}+ v_{it}\\
  v_{it} &=& \alpha_i + \varepsilon_{it}
  \label{eq:REvsFEmodel}
\end{eqnarray}
for $i = 1, \hdots, n$, $t=1, \hdots, T$ where $\varepsilon_{it}$ is iid across $i,t$ with $Var(\varepsilon_{it}) = \sigma^2_{\varepsilon}$ and $\alpha_i$ is iid across $i$ with $Var\left( \alpha_i \right)=\sigma^2_{\alpha}$.
Stacking observations for a given individual over time in the usual way, let $\mathbf{y}_i = (y_{i1}, \hdots, y_{iT})'$ and define $\mathbf{x}_i, \mathbf{v}_i$ and $\boldsymbol{\varepsilon}_i$ analogously.
Our goal in this example is to estimate $\beta$, the effect of $x$ on $y$.
Although $x_{it}$ is uncorrelated with the time-varying portion of the error term, $Cov(x_{it},\varepsilon_{it})=0$, we are unsure whether or not it is correlated with the individual effect $\alpha_i$. 
If we knew for certain that $Cov(x_{it},\alpha_i)=0$, we would prefer to report the ``random effects'' generalized least squares (GLS) estimator given by
\begin{equation}
  \widehat{\beta}_{GLS} = \left(\sum_{i=1}^{n} \mathbf{x}_i' \widehat{\Omega}^{-1} \mathbf{x}_i\right)^{-1}\left(\sum_{i=1}^{n} \mathbf{x}_i'  \widehat{\Omega}^{-1} \mathbf{y}_i   \right)\\
  \label{eq:REdef}
\end{equation}
where $\widehat{\Omega}^{-1}$ is a preliminary consistent estimator of 
\begin{equation}
  \Omega^{-1} = [Var(\mathbf{v}_i)]^{-1} = \frac{1}{\sigma_\epsilon^2} \left[I_T - \frac{\sigma_\alpha^2}{(T\sigma_\alpha^2 + \sigma_\epsilon^2)} \boldsymbol{\iota}_T\boldsymbol{\iota}_T'\right]
  \label{eq:OmegaInvRE}
\end{equation}
and $I_T$ denotes the $T\times 1$ identity matrix and $\boldsymbol{\iota}_T$ a $T$-vector of ones.
This estimator makes efficient use of the variation between and within individuals, resulting in an estimator with a lower variance.
When $Cov(x_{it},\alpha_i)\neq 0$, however, the random effects estimator is biased. 
Although its variance is higher than that of the GLS estimator, the ``fixed effects'' estimator given by 
\begin{equation}
  \widehat{\beta}_{FE} = \left(\sum_{i=1}^{n} \mathbf{x}_i' Q \mathbf{x}_i\bigg)^{-1}\bigg(\sum_{i=1}^{n} \mathbf{x}_i' Q\mathbf{y}_i   \right),
  \label{eq:FEdef}
\end{equation}
where $Q=I_T - \boldsymbol{\iota}_T\boldsymbol{\iota}_T'/T$, remains unbiased even when $x_{it}$ is correlated with $\alpha_i$. 

The conventional wisdom holds that one should use the fixed effects estimator whenever $Cov(x_{it},\alpha_i)\neq 0$.
If the correlation between the regressor of interest and the individual effect is \emph{sufficiently small}, however, the lower variance of the random effects estimator could more than compensate for its bias in a mean-squared error sense.
This is precisely the possibility that we consider here using the GFIC.
In this example, the local mis-specification assumption takes the form
\begin{equation}
  \sum_{t=1}^T E\left[ x_{it}\alpha_i \right] = \frac{\tau}{\sqrt{n}}
  \label{eq:REvsFElocalmisp}
\end{equation}
where $\tau$ is fixed, unknown constant.
In the limit the random effects assumption that $Cov(x_{it},\alpha_i)=0$ holds, since $\tau/\sqrt{n} \rightarrow 0$.
Unless $\tau=0$, however, this assumption \emph{fails} to hold for any finite sample size.
An asymptotically unbiased estimator of $\tau$ for this example is given by
\begin{equation}
  \widehat{\tau}  =( T\widehat{\sigma}_\alpha^2 + \widehat{\sigma}_\epsilon^2) \left[\frac{1}{\sqrt{n}} \sum_{i=1}^n \mathbf{x}_i' \widehat{\Omega}^{-1} (\mathbf{y}_i - \mathbf{x}_i \widehat{\beta}_{FE})\right]
  \label{eq:REvsFEtau}
\end{equation}
leading to the following result, from which we will construct the GFIC for this example.
\begin{thm}[Fixed versus Random Effects Limit Distributions]
\label{thm:REvsFE}
  Let $\left( \mathbf{x}_{ni}, \alpha_{ni}, \boldsymbol{\varepsilon}_{ni} \right)$ be an iid triangular array of random variables such that $Var(\boldsymbol{\varepsilon}_i|\mathbf{x}_{ni},\alpha_{ni})\rightarrow \sigma_{\varepsilon}^2 I_T$, $E[\mathbf{x}_{ni}'Q\boldsymbol{\varepsilon}_{ni}]=0$, and $E\left[ \alpha_i \boldsymbol{\iota}_T'\mathbf{x}_{ni} \right]=\tau/\sqrt{n}$ for all $n$.
  Then, under standard regularity conditions,
\[
  \left[\begin{array}{c}
\sqrt{n} (\widehat{\beta}_{RE} - \beta)\\
\sqrt{n} (\widehat{\beta}_{FE} - \beta)\\
\widehat{\tau}
\end{array}\right] \overset{d}{\rightarrow}  \left( 
\left[\begin{array}{c}
c\tau \\
0  \\
\tau\\
\end{array}\right],  
\left[\begin{array}{ccc}
\eta^2 & \eta^2 & 0 \\
\eta^2 & c^2\sigma^2 + \eta^2 & -c\sigma^2\\ 
0 & -c\sigma^2 & \sigma^2
\end{array}\right] \right)
\]
where $\eta^2 = E[\mathbf{x}_i'\Omega^{-1}\mathbf{x}_i]$, $c = E[\mathbf{x}_i' Q \mathbf{x}_i]/(T\sigma_\alpha^2 + \sigma_\varepsilon^2)$, and
\[\sigma^2 = \frac{(T\sigma_{\alpha}^2 + \sigma_{\varepsilon}^2)^2}{E\left[ \mathbf{x}_i'\Omega^{-1}\mathbf{x}_i \right]}\left( \frac{\sigma_{\varepsilon}^2}{E\left[ \mathbf{x}_i \Omega^{-1} \mathbf{x}_i \right]E\left[ \mathbf{x}_i Q \mathbf{x}_i \right]} - 1 \right). \]
\end{thm}

\begin{proof}[Proof of Theorem \ref{thm:REvsFE}]
  This proof is standard so we provide only a sketch.
  First, let 
  $A_n = (n^{-1}\sum_{i=1}^n \mathbf{x}_i' \widehat{\Omega}^{-1}\mathbf{x}_i)$, $B_n = (n^{-1} \sum_{i=1}^n \mathbf{x}_i' Q\mathbf{x}_i)$, and $C_n = T\widehat{\sigma}_\alpha^2 + \widehat{\sigma}_\varepsilon^2$.
  Now, expanding $\widehat{\beta}_{FE}$, $\mathbf{\beta}_{RE}$, and $\widehat{\tau}$ and re-arranging
\[
  \left[
  \begin{array}{c}
\sqrt{n} (\widehat{\beta}_{RE} - \beta)\\
\sqrt{n} (\widehat{\beta}_{FE} - \beta)\\
\widehat{\tau}
  \end{array}
\right] = 
\left[
\begin{array}{cc}
  A_n^{-1} & 0 \\
  0 & B_n^{-1} \\
  C_n & -C_nA_nB_n^{-1}
\end{array}
\right] \left[
\begin{array}{c}
  n^{-1/2} \sum_{i=1}^n \mathbf{x}_i' \widehat{\Omega}^{-1} \mathbf{v}_i\\ 
  n^{-1/2} \sum_{i=1}^n \mathbf{x}_i' Q\mathbf{v}_i
\end{array}
\right].
\]
The result follows by applying a law of large numbers to $A_n, B_n, C_n$, and $\widehat{\Omega}$ and the Lindeberg-Feller CLT jointly to $n^{-1/2} \sum_{i=1}^n \mathbf{x}_i'Q\mathbf{v}_i$ and $n^{-1/2}\sum_{i=1}^n \mathbf{x}_i' \Omega^{-1} \mathbf{v}_i$. 
\end{proof}


We see from Theorem \ref{thm:REvsFE} that $AMSE(\widehat{\beta}_{RE}) = c^2 \tau^2 + \eta^2$, $AMSE(\widehat{\beta}_{FE}) = c^2\sigma^2 + \eta^2$, and $\widehat{\tau}^2 - \sigma^2$ provides an asymptotically unbiased estimator of $\tau^2$.
Thus, substituting $\widehat{\tau}^2 - \sigma^2$ for $\tau$ and rearranging the preceding AMSE expressions, the GFIC tells us that we should select the random effects estimator whenever $|\widehat{\tau}|\leq \sqrt{2} \sigma$.
To implement this rule in practice, we construct a consistent estimator of $\sigma^2$, for which we require estimators of $\sigma_{\alpha}^2, \sigma_{\varepsilon}^2$ and $\sigma_{v}^2 = Var(\alpha_i + \varepsilon_{it})$.
We estimate these from the residuals
\[
\widehat{\epsilon}_{it} = (y_{it} -\bar{y}_i) - (x_{it} - \bar{x}_i) \widehat{\beta}_{FE}; \quad
\widehat{v}_{it} = y_{it} - x_{it} \widehat{\beta}_{OLS}
\]
where $\widehat{\beta}_{OLS}$ denotes the \emph{pooled} OLS estimator of $\beta$, leading to the variance estimators 
\[
\widehat{\sigma}_\alpha^2 = \widehat{\sigma}_v^2 - \widehat{\sigma}_\epsilon^2; \quad
\widehat{\sigma}_\epsilon^2 = \frac{1}{n(T-1)-1} \sum_{i=1}^n \sum_{t=1}^T \widehat{\epsilon}_{it}^2; \quad
\widehat{\sigma}_v^2 = \frac{1}{nT-1} \sum_{i=1}^n \sum_{t=1}^T \widehat{v}_{it}^2
\]

Selection, of course, is a somewhat crude procedure: it is essentially an average that uses all-or-nothing weights.
As a consequence, relatively small changes to the data could produce discontinuous changes in the weights, leading to a procedure with a high variance.
Rather than selecting between the random effects and fixed effects estimators based on estimated AMSE, an alternative idea is to consider a more general weighted average of the form
\[\widetilde{\beta}(\omega) =  \omega \widehat{\beta}_{FE} + (1 - \omega)\widehat{\beta}_{RE}\]
and for $\omega \in [0,1]$ \emph{optimize} the choice of $\omega$ to minimize AMSE. 
From Theorem \ref{thm:REvsFE} we see that the AMSE-minimizing value of $\omega$ is $\omega^* = (1 + \tau^2/\sigma^2)^{-1}$.
Substituting our asymptotically unbiased estimator of $\tau^2$ and our consistent estimator $\widehat{\sigma}^2$ of $\sigma^2$, we propose the following plug-in estimator of $\omega^*$ 
\begin{equation*}
  \omega^* = \left[ 1 + \frac{ \max\left\{  \widehat{\tau}^2 - \widehat{\sigma}^2, 0\right\}}{\widehat{\sigma}^2} \right]^{-1}
\end{equation*}
where we take the maximum over $\widehat{\tau}^2 - \widehat{\sigma}^2$ and zero so that $\widehat{\omega}^*$ is between zero and one. 
