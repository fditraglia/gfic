%!TEX root = main.tex
\section{Introduction}

An econometric model is a tool for answering a particular research question: different questions may suggest different models for the same data. 
And the fact that a model is wrong, as the old saying goes, does not prevent it from being useful. 
This paper proposes a novel selection criterion for GMM estimation that takes both of these points to heart: the generalized focused information criterion (GFIC). 
Rather than attempting to identify the correct specification, the GFIC chooses from a set of potentially mis-specified moment conditions and parameter restrictions to yield the smallest mean squared error (MSE) estimator of a user-specified scalar target parameter. 
We derive the GFIC under local mis-specification, using asymptotic mean squared error (AMSE) to approximate finite-sample MSE. 
In this framework mis-specification, while present for any fixed sample size, disappears in the limit so that asymptotic variance and squared bias remain comparable. 
GMM estimators remain consistent under local mis-specification but their limit distributions show an asymptotic bias. 
Adding an additional moment condition or imposing a parameter restriction generally reduces asymptotic variance but, if incorrectly specified, introduces a source of bias.
The GFIC trades off these two effects in the first-order asymptotic expansion of an estimator to approximate its finite sample behavior.

The GFIC takes its motivation from a situation that is common in empirical practice.
A researcher who hopes to estimate a parameter of interest $\mu$ must decide which assumptions to use.
On the one hand is a set of relatively uncontroversial ``baseline'' assumptions.
We suppose that the baseline assumptions are correct and identify $\mu$.
But the very fact that that the baseline assumptions do not raise eyebrows suggests that they may not be especially informative about $\mu$. 
On the other hand are one or more stronger controversial ``suspect'' assumptions.
These stronger assumptions are expected to be much more informative about $\mu$.
If we were certain that they were correct, we would definitely choose to impose them in estimation.
Indeed, by continuity, even if they were \emph{nearly} correct, imposing the suspect assumptions could yield a favorable bias-variance tradeoff.
This is the essential idea behind the GFIC.
When the baseline assumptions identify the model, the GFIC provides an asymptotically unbiased estimator of AMSE.

The GFIC is an extension of the focused moment selection criterion (FMSC) of \cite{DiTraglia2016}.
While the FMSC considers the problem of selecting moment conditions while holding the model specification \emph{fixed}, the GFIC allows us to select over both aspects of our specification simultaneously.
This extension is particularly valuable in panel data applications, where we may, for example, wish to carry out selection over the lag specification as well as the exogeneity assumptions used to estimate a dynamic panel model.
We specialize the GFIC to a dynamic panel example below, in addition to two others: selecting between random and fixed effects estimators, and choosing between pooled OLS and mean-group estimators of an average effect in the presence of heterogeneity.  
In addition to extending the FMSC to a broader class of problems and deriving specific results for well-known panel data problems, we also extend the results of \cite{DiTraglia2016} on post-selection and moment-average estimators to the more general setting of the GFIC.  
In the random versus fixed effects example, we further derive a novel averaging estimator that optimally combines the information contained in the two specifications.
The GFIC and averaging estimator perform well in simulation studies for our examples.
We conclude with an empirical example applying the GFIC to a panel data model for the price elasticity of cigarette demand. 

As its name suggests, the GFIC is related to the focused information criterion (FIC) of \cite{ClaeskensHjort2003}, a model selection procedure for maximum likelihood estimators that uses local mis-specification to approximate the MSE of a target parameter. 
%The idea of targeted, risk-based model selection has proved popular in recent years, leading to a number of interesting extensions. 
%\cite{HjortClaeskens2006}, for example, propose an FIC for the Cox proportional hazards model while \cite{ClaeskensCarroll} extend the FIC more generally to problems in which the likelihood involves an infinite-dimensional parameter but selection is carried out over the parametric part. 
%More recently, \cite{ZhangLiang} extend the FIC to generalized additive partially linear models and \cite{BehlClaeskensDette} develop an FIC for quantile regression.
%While MSE is a natural risk-function for asymptotically normal estimators, different applications of model selection may call for different risk functions. \cite{ClaeskensCroux2006}, for example, suggest combining local mis-specification with $L_p$-risk or mis-classification error rates to derive an FIC better-suited to prediction in logistic regression models. 
%In a similar vein, the weighted FIC (wFIC) of \cite{ClaeskensHjort2008} provides a potentially important tool for policy analysis, allowing researchers to choose the model that minimizes weighted average risk for generalized linear models. 
%While the FIC can be used, for example, to choose the best model for estimating the mean response at a given set of covariate values, the wFIC allows us to minimize the expected mean response over a \emph{distribution} of covariate values corresponding to some target population.
%In time series problems, predictive MSE is typically more interesting than estimator MSE.
%Accordingly, \cite{ClaeskensCroux} develop an FIC to minimize forecast MSE in autoregressive models where the true order of the process is infinite. 
%Independently of the FIC literature, \cite{Schorfheide2005} likewise uses local mis-specification to suggest a procedure for using finite order vector autoregressions to forecast an infinite-order vector moving average process with minimum quadratic loss. 
%This idea shares similarities with \cite{Skouras2001}.
Like the FIC and related proposals, e.g.\ \cite{Schorfheide2005}, the GFIC uses local mis-specification to derive a risk-based selection criterion.
Unlike them, however, the GFIC provides both moment and model selection for general GMM estimators. 
If the moment conditions used in estimation are the score of a maximum likelihood model and we consider model selection only, then the GFIC reduces to the FIC.
Thus, the GFIC extends both the FIC and the FMSC of \cite{DiTraglia2016}.
Comparatively few papers propose criteria for simultaneous GMM model and moment selection under mis-specification.\footnote{See \cite{Smith1992} for an approach to GMM model selection based on non-nested hypothesis testing. For a detailed discussion of the literature on moment selection, see \cite{DiTraglia2016}.} \cite{AndrewsLu} propose a family of selection criteria by adding appropriate penalty and ``bonus'' terms to the J-test statistic, yielding analogues of AIC, BIC, and the Hannan-Quinn information criterion.
\cite{HongPrestonShum} extend this idea to generalized empirical likelihood (GEL). 
The principal goal of both papers is consistent selection: they state conditions under which the correct model and all correct moment conditions are chosen in the limit. 
As a refinement to this approach, \cite{LaiSmallLiu} suggest a two-step procedure: first consistently eliminate incorrect models using an empirical log-likelihood ratio criterion, and then select from the remaining models using a bootstrap covariance matrix estimator. 
The point of the second step is to address a shortcoming in the standard limit theory. 
While first-order asymptotic efficiency requires that we use all available correctly specified moment conditions, this can lead to a deterioration in finite sample performance if some conditions are only weakly informative.
\cite{HallPeixe2003} make a similar point about the dangers of including ``redundant'' moment conditions while \cite{Caner2009} proposes a lasso-type GMM estimator to consistently remove redundant parameters.


In contrast to these suggestions, the GFIC does not aim to identify the correct model and moment conditions: its goal is a low MSE estimate of a quantity of interest, even if this entails using a specification that is not exactly correct.  
As such, the GFIC is an ``efficient'' rather than a consistent selection criterion.
There is an unavoidable trade-off between consistent selection and estimators with desirable risk properties \citep{Yang2005}.
Indeed, the worst-case risk of any consistent selection procedure is \emph{unbounded} as sample size tends to infinity \citep{LeebPoetscher2008}.
In this sense, the fact that the GFIC is not consistent is a benefit rather than a liability.
As we show in simulations below, its worst-case performance is much better than that of competing selection procedures.

Although not strictly a selection procedure, the combined moments (CM) estimator of \cite{JudgeMittelhammer} takes a similar perspective to that of the GFIC, emphasizing that incoporating the information from an incorrect specification could lead to a favorable bias-variance tradeoff under the right circumstances. 
Their proposal uses a Cressie-Read divergence measure to combine the information from competing moment specifications, for example OLS versus two-stage least squares, yielding a data-driven compromise estimator. 
Unlike the GFIC, however, the CM estimator is not targeted to a particular research goal.
A key point of the GFIC is that two different researchers working with the same dataset may find it optimal to use different specifications.
We explore this idea further in our dynamic panel example below.

The remainder of this paper is organized as follows. Section \ref{sec:asymp} derives the asymptotic distribution of GMM estimators under locally mis-specified moment conditions and parameter restrictions. 
Section \ref{sec:GFIC} uses this information to calculate the AMSE of a user-specified target parameter and provides asymptotically unbiased estimators of the required bias parameters, yielding the GFIC. 
Section \ref{sec:avg} extends the results on averaging estimators and post-selection inference from \cite{DiTraglia2016} to the more general setting of this paper.
Section \ref{sec:examples} specializes the GFIC to three panel data examples, and Section \ref{sec:simulation} presents simulation results.
Finally, Section \ref{sec:cigarettes} presents our empirical example and  Section \ref{sec:conclude} concludes.  
Proofs and supplementary simulation results appear in the Appendix.

