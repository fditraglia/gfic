%!TEX root = main.tex
\section{Proofs}
\begin{proof}[Proof of Theorem \ref{thm:asymp}]
By a mean-value expansion around $(\gamma_0,\theta_0)$,
	$$\sqrt{n}\left(\widehat{\beta}(b,c) - \beta_0^{(b)}\right) = - K(b,c)\Xi_c \sqrt{n} f_n(\gamma_0,\theta_0) + o_p(1)$$
  and by assumption \ref{assump:high-level},
$\sqrt{n} f_n(\gamma_0,\theta_0) - \sqrt{n}E\left[f(Z_{ni},\gamma_0,\theta_0) \right]\overset{d}{\rightarrow} (\mathscr{N}_g', \mathscr{N}_h')'$. 
Now, by a mean-value expansion around $\gamma_n$,
	\begin{align*}
		\sqrt{n}E\left[ f(Z_{ni}, \gamma_0, \theta_0) \right] &= \sqrt{n}E\left[ f(Z_{ni}, \gamma_n,\theta_0) \right] + \sqrt{n}\nabla_{\gamma'}E\left[ f(Z_{ni}, \bar{\gamma},\theta_0) \right] (\gamma_0 -\gamma_n)\\
			&=\left(\left[ \begin{array}{c} 0\\ \tau\end{array}\right] - \nabla_{\gamma'}E\left[ f(Z_{ni}, \bar{\gamma},\theta_0) \right] \delta\right) \rightarrow \left(\left[ \begin{array}{c} 0\\ \tau\end{array}\right] - F_\gamma\delta\right).
	\end{align*}
  Hence, $\sqrt{n}f_n(\gamma_0, \theta_0) \overset{d}{\rightarrow} (\mathscr{N}_g', \mathscr{N}_h')' + (0', \tau')' - F_\gamma \delta$.
  The result follows by the continuous mapping theorem.
\end{proof}

\begin{proof}[Proof of Corollary \ref{cor:valid}]
Since $\Xi_c$ picks out only the components corresponding to $g$,
For the valid estimator,
	$$\Xi_c \left(\left[\begin{array}{c} \mathscr{N}_g\\  \mathscr{N}_h\end{array}\right]+ \left[ \begin{array}{c} 0\\ \tau\end{array}\right] - F_\gamma\delta\right) =  \mathscr{N}_g - G_\gamma \delta.$$
Thus, $\sqrt{n}\left( \widehat{\beta}_v - \beta_0 \right) \overset{d}{\rightarrow} -K_v\left(\mathscr{N}_g - G_\gamma \delta\right)$.
Finally, by the definition of a matrix inverse,
	\begin{align*}
		K_v G_\gamma \delta
    %&= \left(\left[\begin{array}{c}G_\gamma' \\ G_\theta'\end{array}\right] W_{gg} \left[\begin{array}{cc} G_\gamma & G_\theta \end{array}\right] \right) \left[\begin{array}{c}G_\gamma' \\ G_\theta'\end{array}\right]W_{gg} G_\gamma\delta\\ \\
			&= \left[\begin{array}{cc} 
				G_\gamma'W_{gg}G_\gamma & G_\gamma'W_{gg}G_\theta\\
				G_\theta'W_{gg}G_\gamma & G_\theta'W_{gg}G_\theta
			\end{array} \right]^{-1}
			\left[\begin{array}{c}
				G_\gamma'W_{gg}G_\gamma\\
				G_\theta'W_{gg}G_\gamma
			\end{array}\right]\delta =\left[\begin{array}{c} 0\\ \delta\end{array}\right].
	\end{align*}
\end{proof}


\begin{proof}[Proof of Corollary \ref{cor:mulimit}]
For some $\bar{\gamma}$ between $\gamma_0$ and $\gamma_n = \gamma_0 +\delta/\sqrt{n}$. 
		\[\mu_n  = \varphi(\gamma_0,\theta_0)+ \nabla_\gamma \varphi(\bar{\gamma},\theta_0)'(\gamma_n - \gamma_0) = \mu_0 + \nabla_\gamma \varphi(\bar{\gamma},\theta_0)' \delta/\sqrt{n}\]
by a mean-value expansion.
Hence, $\sqrt{n}(\mu_n - \mu_0) = \nabla_\gamma \varphi(\bar{\gamma},\theta_0)' \delta \rightarrow \nabla_\gamma \varphi(\gamma_0,\theta_0)' \delta$.
The result follows since $\sqrt{n}\left(\widehat{\mu}(b,c) - \mu_n \right)  = \sqrt{n}\left( \widehat{\mu}(b,c) - \mu_0 \right) - \sqrt{n}\left(\mu_n - \mu_0\right)$.
\end{proof}


\begin{proof}[Proof of Corollary \ref{cor:muvalid}]
The result follows from Corollaries \ref{cor:valid} and \ref{cor:mulimit} since,
	\begin{eqnarray*}
		\sqrt{n}\left( \widehat{\mu}_v - \mu_n\right) &\overset{d}{\rightarrow}&\nabla_\beta\varphi_0' \left\{ \left[\begin{array}{c} 0\\ \delta \end{array}\right] -K_v\mathscr{N}_g  \right\}-\nabla_\gamma \varphi_0' \delta\\ 
			&=& -\nabla_\beta\varphi_0' K_v\mathscr{N}_g + \left[\begin{array}{cc} \nabla_\theta\varphi_0'  & \nabla_\gamma\varphi_0' \end{array}\right]\left[\begin{array}{c} 0\\ \delta\end{array}\right]-\nabla_\gamma \varphi_0' \delta\\
			&=& -\nabla_\beta(\gamma_0,\theta_0)' K_v\mathscr{N}_g.
	\end{eqnarray*}
\end{proof}


\begin{proof}[Proof of Lemma \ref{lem:tauhatasymp}]
By a mean-value expansion around $\beta_0 = ( \gamma_0', \theta_0')'$,
\[
  \sqrt{n}h_n\left(\widehat{\beta}_v \right) = \sqrt{n}h_n(\beta_0) + H \sqrt{n} \left(\widehat{\beta}_v - \beta_0\right) + o_p(1).
\]
Now, since
\[
  \sqrt{n}f_n(\gamma_0,\theta_0) \overset{d}{\rightarrow} \left[\begin{array}{c} \mathscr{N}_g\\  \mathscr{N}_h\end{array}\right]+ \left[ \begin{array}{c} 0\\ \tau\end{array}\right] - \left[\begin{array}{c}G_\gamma\\ H_\gamma \end{array}\right]\delta
\]
we have $\sqrt{n}h_n(\gamma_0,\theta_0)\overset{d}{\rightarrow} \mathscr{N}_h + \tau - H_\gamma \delta$.
Substituting, 
	\begin{align*}
		\sqrt{n}h_n(\widehat{\beta}_v) &\overset{d}{\rightarrow}  \mathscr{N}_h + \tau - H_\gamma \delta+ H\left( -K_v \mathscr{N}_g + \left[\begin{array}{c} 0 \\ \delta \end{array} \right]\right)
			%&= \mathscr{N}_h + \tau - H_\gamma \delta - HK_v \mathscr{N}_g + \left[ \begin{array}{cc} H_\theta & H_\gamma \end{array}\right] \left[\begin{array}{c} 0 \\ \delta \end{array} \right]\\
			%&= \mathscr{N}_h  + \tau - H_\gamma \delta - HK_v \mathscr{N}_g  + H_\gamma \delta\\
			= \tau - HK_v \mathscr{N}_g + \mathscr{N}_h.
	\end{align*}
\end{proof}

\begin{proof}[Proof of Corollary \ref{cor:biasestimators}]
  Define $(U', V')' = (\delta', \tau')' + \Psi (\mathscr{N}_g', \mathscr{N}_h')'$. 
	%$$\left[\begin{array}{c} U\\ V \end{array}\right]=\left[\begin{array}{c}\delta\\ \tau\end{array} \right] +\Psi\left[\begin{array}{c}\mathscr{N}_g \\ \mathscr{N}_h \end{array}\right].$$
By the Continuous Mapping Theorem and Theorem \ref{thm:jointbias},
	$$\left[\begin{array}{c} \widehat{\delta} \\ \widehat{\tau} \end{array}\right]\left[\begin{array}{cc} \widehat{\delta}' & \widehat{\tau}'\end{array} \right] \overset{d}{\rightarrow} \left[\begin{array}{c} U\\V \end{array}\right]\left[\begin{array}{cc}U' & V'\end{array} \right] $$
The result follows since
$$\Psi\Omega\Psi' =Var\left[\begin{array}{c}U\\V\end{array}\right] = 
E\left[\begin{array}{cc} 
				UU'&UV'\\
				VU'&VV'
				\end{array}\right] - 
				\left[\begin{array}{cc}
				\delta\delta'&\delta\tau'\\
				\tau\delta'&\tau\tau'
				\end{array}\right].$$
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:REvsFE}]
  This proof is standard so we provide only a sketch.
  First, let 
  $A_n = (n^{-1}\sum_{i=1}^n \mathbf{x}_i' \widehat{\Omega}^{-1}\mathbf{x}_i)$, $B_n = (n^{-1} \sum_{i=1}^n \mathbf{x}_i' Q\mathbf{x}_i)$, and $C_n = T\widehat{\sigma}_\alpha^2 + \widehat{\sigma}_\varepsilon^2$.
  Now, expanding $\widehat{\beta}_{FE}$, $\mathbf{\beta}_{RE}$, and $\widehat{\tau}$ and re-arranging
\[
  \left[
  \begin{array}{c}
\sqrt{n} (\widehat{\beta}_{RE} - \beta)\\
\sqrt{n} (\widehat{\beta}_{FE} - \beta)\\
\widehat{\tau}
  \end{array}
\right] = 
\left[
\begin{array}{cc}
  A_n^{-1} & 0 \\
  0 & B_n^{-1} \\
  C_n & -C_nA_nB_n^{-1}
\end{array}
\right] \left[
\begin{array}{c}
  n^{-1/2} \sum_{i=1}^n \mathbf{x}_i' \widehat{\Omega}^{-1} \mathbf{v}_i\\ 
  n^{-1/2} \sum_{i=1}^n \mathbf{x}_i' Q\mathbf{v}_i
\end{array}
\right].
\]
The result follows by applying a law of large numbers to $A_n, B_n, C_n$, and $\widehat{\Omega}$ and the Lindeberg-Feller CLT jointly to $n^{-1/2} \sum_{i=1}^n \mathbf{x}_i'Q\mathbf{v}_i$ and $n^{-1/2}\sum_{i=1}^n \mathbf{x}_i' \Omega^{-1} \mathbf{v}_i$. 
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:limitDpanel}.]
  This proof is standard, so we provide only a sketch.
Expanding, 
\begin{align*}
  \sqrt{n}\left[\widehat{\beta}(k,\cdot) - \beta\right] &=(0, \mathbf{0}_{k-1}', \delta)' + \widehat{Q}(k,\cdot)\left[ n^{-1/2}Z'(k,\cdot)\Delta \mathbf{v}\right]\\
  \sqrt{n}\left[\widehat{\beta}(r,\cdot) - \beta_{r}\right] &=  \widehat{Q}(r,\cdot)\left\{ \delta \left[n^{-1}Z'(r,\cdot) L^{k}\Delta \mathbf{y}^+\right] + \left[n^{-1/2}Z'(r,\cdot)\Delta \mathbf{v}^{+}\right] \right\}
\end{align*}
The result follows, after some algebra, by applying the Lindeberg-Feller CLT to $n^{-1/2}Z'(k,\cdot)\Delta \mathbf{v}$ and $n^{-1/2}Z'(r,\cdot)\Delta \mathbf{v}^{+}$ and an appropriate law of large numbers to $n^{-1} Z'(r,\cdot)L^k \Delta \mathbf{y}^{+}$, where $(\cdot)$ is either $\text{P}$ or $\text{S}$ depending on the instrument set used.
\end{proof}


\begin{proof}[Proof of Theorem \ref{thm:DpanelJoint}]
  Expanding $\widehat{\beta}(k,\text{P})$ from Equation \ref{eq:DpanelEstimators} 
  \begin{align*}
    n^{-1/2}X'\left[ \Delta \mathbf{y} - W(k)\widehat{\beta}(k,\text{P})  \right] 
    %&= n^{-1/2}X'\left\{ \left[W(k) \beta_n + \Delta \mathbf{v}\right] - W(k) \left[ \beta_n + \widehat{Q}(k,\text{P}) n^{-1} Z'(k,\text{P})\Delta \mathbf{v} \right] \right\} \\
    &= n^{-1/2}X'\left[ \Delta \mathbf{v}  - W(k)\, \widehat{Q}(k,\text{P}) \, n^{-1} Z'(k,\text{P})\Delta \mathbf{v}\right] \\
    %&= n^{-1/2}X'\Delta \mathbf{v}  - n^{-1}X'W(k)\,\widehat{Q}(k,\text{P})\left[ n^{-1/2} Z'(k,\text{P})\Delta \mathbf{v}\right]\\
    &= \left[
    \begin{array}{cc}
      -n^{-1} X'W(k) \, \widehat{Q}(k,\text{P}) & I_{T-k-1}
    \end{array}
  \right] 
  \left[
  \begin{array}{c}
    n^{-1/2}Z'(k,\text{P}) \Delta \mathbf{v} \\
    n^{-1/2} X' \Delta \mathbf{v}
  \end{array}
\right]
  \end{align*}
  using $\Delta \mathbf{y} = W(k) \beta_n + \Delta \mathbf{v}$. 
  Similarly, expanding $\widehat{\beta}(k,\text{P})$ from Equation \ref{eq:DpanelEstimators},
  \[
    \sqrt{n}\left[ \widehat{\beta}(k,\text{P}) \right] = \left[
    \begin{array}{ccc}
      0 & \mathbf{0}_{k-1} & \delta  
    \end{array}
  \right] + \widehat{Q}(k,\text{P}) n^{-1/2}Z'(k,\text{P}) \Delta \mathbf{v}
  \]
  and since $\widehat{\delta}$ is $\sqrt{n}$ times the $k$\textsuperscript{th} element of $\widehat{\beta}(k,\text{P})$ and the $k$\textsuperscript{th} element $\beta$ is zero, we have
  \[
    \widehat{\delta} = \delta + \left[
    \begin{array}{ccc}
    0 & \mathbf{0}'_{k-1} & 1  
    \end{array}
  \right] \widehat{Q}(k,\text{P}) n^{-1/2} Z'(k,\text{P})\Delta \mathbf{v}.
  \]
  By a law of large numbers $\widehat{Q}(k,\text{P}) \rightarrow_p Q(k,\text{P})$ and $n^{-1}X'W(k) \rightarrow_p \boldsymbol{\xi}' \otimes \boldsymbol{\iota}_{T-k-1}$, hence 
  \[
    \left[
    \begin{array}{c}
      \widehat{\delta} - \delta \\ \widehat{\tau}
    \end{array}
  \right] = \Psi
  \left[
  \begin{array}{c}
    n^{-1/2}Z'(k,\text{P}) \Delta \mathbf{v} \\
    n^{-1/2} X' \Delta \mathbf{v}
  \end{array}
\right] + o_p(1).
  \]
  The result follows, after some algebra, by applying the Lindeberg-Feller CLT jointly to $n^{-1/2}Z'(k,\text{P})\Delta\mathbf{v}$ and $n^{-1/2}X'\Delta \mathbf{v}$ and noting that the permutation matrix $\Pi$ maps the vector $[n^{-1/2}Z'(k,\text{S})\Delta \mathbf{v}]$ to the vector $\left[
  \begin{array}{cc}
    \left\{n^{-1/2} Z'(k,P)\Delta \mathbf{v}\right\}' &
    \left\{n^{-1/2} X'\Delta \mathbf{v}\right\}' 
  \end{array}
\right]'.$
\end{proof}


\begin{proof}[Proof of Theorem \ref{thm:OLSvsMG}]
Expanding the definitions of the OLS and mean-group estimators, 
\begin{align*}
  \sqrt{n} (\widehat{\beta}_{OLS} - \beta) &=  \left[\begin{array}{cc}
    \left(n^{-1}\sum_{i=1}^{n} \mathbf{x}_i'  \mathbf{x}_i\right)^{-1} & \left(n^{-1}\sum_{i=1}^{n} \mathbf{x}_i'  \mathbf{x}_i\right)^{-1}\end{array} \right] 
  \left[\begin{array}{c} 
n^{-1/2}\sum_{i=1}^{n} \mathbf{x}_i'\mathbf{x}_i\mathbf{\eta}_i   \\
n^{-1/2}\sum_{i=1}^{n} \mathbf{x}_i'\mathbf{\epsilon}_i   
\end{array}\right]\\
\sqrt{n} (\widehat{\beta}_{MG} - \beta)  &=  n^{-1/2} \sum_{i=1}^n \left[\eta_i + (\mathbf{x}_i'\mathbf{x}_i)^{-1} \mathbf{x}_i'\epsilon_i\right]
\end{align*}
and proceeding similarly for $\widehat{\tau}$,
\[
\widehat{\tau}  =  
\left[
  \begin{array}{ccc}
  1 & 1& -n^{-1}\sum_{i=1}^n \mathbf{x}_i'\mathbf{x}_i
\end{array}\right] 
\left[\begin{array}{c}
n^{-1/2} \sum_{i=1}^n \mathbf{x}_i'\mathbf{x}_i \eta_i \\
n^{-1/2} \sum_{i=1}^n \mathbf{x}_i'\epsilon_i\\
n^{-1/2} \sum_{i=1}^n \left\{ \eta_i + (\mathbf{x}_i'\mathbf{x}_i)^{-1} \mathbf{x}_i'\epsilon_i\right\} 
\end{array}
\right].
\]
The result follows, after some algebra, by a LLN and the Lindeberg-Feller CLT.
\end{proof}
