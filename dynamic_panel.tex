%!TEX root = main.tex
\section{Dynamic Panel Example}
\label{sec:Dpanel}
We now specialize the GFIC to a dynamic panel model of the form 
\begin{equation}
  y_{it} = \theta x_{it} + \gamma_1 y_{it-1} + \cdots + \gamma_k y_{it-k} + \eta_i + v_{it}
  \label{eq:truepanel}
\end{equation}
where $i = 1, \hdots, n$ indexes individuals and $t=1, \hdots, T$  indexes time periods. 
For simplicity, and without loss of generality, we suppose that there are no exogenous time-varying regressors and that all random variables are mean zero.\footnote{Alternatively, we can simply de-mean and project out any time-varying exogenous covariates after taking first-differences.} 
The unobserved error $\eta_i$ is a correlated individual effect: $\sigma_{x\eta}\equiv \mathbb{E}\left[ x_{it}\eta_i \right]$ may not equal zero. 
The endogenous regressor $x_{it}$ is assumed to be predetermined but not necessarily strictly exogenous: $\mathbb{E}[x_{it} v_{is}]=0$ for all $s \geq t$ but may be nonzero for $s < t$.  
We assume throughout that $y_{it}$ is stationary, which requires both $x_{it}$ and $u_{it}$ to be stationary and $|\boldsymbol{\gamma}| < 1$ where $\boldsymbol{\gamma} = (\gamma_1, \dots, \gamma_k)'$.
Our goal is to estimate one of the following two target parameters with minimum MSE: 
\begin{equation}
  \mu_{\text{SR}} \equiv \theta, \quad \quad 
  \mu_{\text{LR}} \equiv \theta / \left[1- (\gamma_1 + \cdots + \gamma_k)\right]
  \label{eq:paneltarget}
\end{equation}
where $\mu_{\text{SR}}$ denotes the short-run effect and $\mu_{\text{LR}}$ the long-run effect of $x$ on $y$.

The question is which assumptions to use in estimation.
Naturally, the answer may depend on whether our target is $\mu_{SR}$ or $\mu_{LR}$.
Our first decision is what assumption to impose on the relationship between $x_{it}$ and $v_{it}$.
This is the \emph{moment selection} decision.
We assumed above that $x$ is predetermined.
Imposing the stronger assumption of strict exogeneity gives us more and stronger moment conditions, but using these in estimation introduces a bias if $x$ is not in fact strictly exogenous.
Our second decision is how many lags of $y$ to use in estimation.
This is the \emph{model selection} decision.
The true model contains $k$ lags of $y$.
If we estimate only $r < k$ lags we not only have more degrees of freedom but more observations: every additional lag of $y$ requires us to drop one time period from estimation. 
In the short panel datasets common in microeconomic applications, losing even one additional time period can represent a substantial loss of information.
At the same time, unless $\gamma_{r+1} = \cdots = \gamma_k = 0$, failing to include all $k$ lags in the model introduces a bias.
%In this example, the GFIC simultaneously chooses over exogeneity assumptions for $x$ and lag length for $y$ to optimally trade off bias and variance.

To eliminate the individual effects $\eta_i$ we work in first differences.
Defining $\Delta$ in the usual way, so that $\Delta y_{it} = y_{it} - y_{it-1}$ and so on, we can write Equation \ref{eq:truepanel} as
\begin{align}
  \Delta y_{it} = \theta \Delta x_{it} + \gamma_1 \Delta y_{it-1} + \cdots + \gamma_k \Delta y_{it-k}  + \Delta v_{it}.
  \label{eq:truepaneldiff}
\end{align}
For simplicity and to avoid many instruments problems -- see e.g.\ \cite{Roodman} -- we focus here on estimation using the instrument sets
\begin{align}
  \mathbf{z}'_{it}(\ell, \text{P}) &\equiv \left[
  \begin{array}{cccc}
    y_{it-2} & \cdots & y_{it-(\ell + 1)} & x_{it-1}
  \end{array}
\right] & 
\mathbf{z}'_{it}(\ell,\text{S}) &\equiv \left[
\begin{array}{cc}
  \mathbf{z}_{it}'(\ell,\text{P}) & x_{it}
\end{array}
\right]
\label{eq:Zdpanel}
\end{align}
similar to \cite{AndersonHsiao}.
Modulo a change in notation, one could just as easily proceed using the instrument sets suggested by \cite{ArellanoBond}.
We use $\ell$ as a placeholder for the lag length used in estimation.
If $\ell = 0$, $\mathbf{z}'_{it}(0,\text{P}) = x_{it-1}$ and $\mathbf{z}'_{it}(0,\text{S}) = (x_{it-1}, x_{it})$.
Given these instrument sets, we have $(\ell + 1)\times (T -\ell - 1)$ moment conditions if $x$ is assumed to be predetermined versus $(\ell + 2)\times (T - \ell - 1)$ if it is assumed to be strictly exogenous, corresponding to the instrument matrices
  $Z_i(\ell,\text{P}) = \mbox{diag}\left\{ \mathbf{z}'_{it}(\ell,\text{P})  \right\}_{t = \ell + 2}^T$ and  $Z_i(\ell,\text{S}) = \mbox{diag}\left\{\mathbf{z}'_{it}(\ell,\text{S}) \right\}_{t = \ell +2}^T$.
To abstract for a moment from the model selection decision, suppose that we estimate a model with the true lag length: $\ell = k$.
The only difference between the P and S sets of moment conditions is that the latter adds over-identifying information in the form of $E[x_{it}\Delta v_{it}]$.
If $x$ is strictly exogenous, this expectation equals zero, but if $x$ is only predetermined, then $E[x_{it}\Delta v_{it}] = -E[x_{it}v_{it-1}] \neq 0$ so the over-identifying moment condition is invalid.
Given our instrument sets, this is the only violation of strict exogeneity that is relevant for our moment selection decision so we take $E[x_{it}v_{it-1}] = -\tau/\sqrt{n}$.

In the examples and simulations described below we consider two-stage least squares (TSLS) estimation of $\mu_{SR}$ and $\mu_{LR}$ using the instruments defined in Equation \ref{eq:Zdpanel}. 
Without loss of generality, we select between two lag length specifications: the first is correct, $\ell = k$, and the second includes $m$ lags too few: $\ell = r$ where $r = k-m$.
Accordingly, we make the coefficients associated with the $(r+1)$\textsuperscript{th}, $\ldots, k$\textsuperscript{th} lags local to zero.
Let $\boldsymbol{\gamma}' = (\gamma_1, \cdots, \gamma_{k-1}, \gamma_{k})$ denote the full vector of lag coefficients and $\boldsymbol{\gamma}_{r}' = (\gamma_1, \cdots, \gamma_{r})$ denote the first $r = k-m$ lag coefficients.
Then, the true parameter vector is $\beta_n = (\theta, \boldsymbol{\gamma}'_{r}, \boldsymbol{\delta}'/\sqrt{n})'$ which becomes, in the limit, $\beta = (\theta, \boldsymbol{\gamma}'_r, \boldsymbol{0}')'$. Both $\boldsymbol{\delta}$ and $\boldsymbol{0}$ are of length $m$. 
To indicate the subvector of $\beta$ that excludes the $(r+1)$\textsuperscript{th}, $\ldots, k$\textsuperscript{th} lag coefficients, let $\beta_{r} = (\theta, \boldsymbol{\gamma}_r')'$. 
%Lastly, let $\boldsymbol{\gamma}_{r^c}' = (\gamma_{r+1}, \gamma_{r+2}, \ldots, \gamma_k)$ which includes the last $m$ lag coefficients.

Because the two lag specifications we consider use different time periods in estimation, we require some additional notation to make this clear. 
First let
$\Delta \mathbf{y}_{i} = [\Delta y_{i,k+2}, \cdots, \Delta y_{iT}]'$ and $\Delta \mathbf{y}^+_{i} = [\Delta y_{i,k+2-m}, \Delta y_{i,k+2-(m-1)}, \cdots, \Delta y_{iT}]'$ 
where the superscript ``+'' indicates the inclusion of $m$ additional time periods: $t = k+2-m, \ldots, k+1$.
Define $\Delta \mathbf{x}_i$, $\Delta \mathbf{x}_{i}^{+}$, $\Delta \mathbf{v}_i$, and $\Delta \mathbf{v}_{i}^{+}$ analogously.
Next, define $L^{r+1}\Delta \mathbf{y}_i^{+} = [\Delta y_{i1}, \Delta y_{i2}, \cdots, \Delta y_{iT-(r+1)}]'$ where $L^{r+1}$ denotes the element-wise application of the $(r+1)$\textsuperscript{th} order lag operator.
Note that the first element of $L^{r+1}\Delta \mathbf{y}_{i}^{+}$ is unobserved since $\Delta y_{i1} = y_{i1} - y_{i0}$ but $t=1$ is the first time period.
Now we define the matrices of regressors for the two specifications: 
\begin{align*}
  W_i^{+'}(r) &= \left[
  \begin{array}{ccccc}
    \Delta \mathbf{x}_i^+ & L \Delta \mathbf{y}_i^{+} &  L^2 \Delta \mathbf{y}_i^{+} & \cdots & L^{r}\Delta \mathbf{y}_i^{+} 
  \end{array}
\right]\\
  W_i'(k) &= \left[
  \begin{array}{cccccc}
    \Delta \mathbf{x}_i & L \Delta \mathbf{y}_i &  L^2 \Delta \mathbf{y}_i & \cdots & L^{k-1}\Delta \mathbf{y}_i & L^k\Delta \mathbf{y}_i 
  \end{array}
\right].
\end{align*}
Note that $W_i^{+}(r)$ contains $m$ more rows than $W_i(k)$ but $W_i(k)$ contains $m$ more columns than $W_i^{+}(r)$: removing the $(r+1)$\textsuperscript{th}, $\ldots, k$\textsuperscript{th} lags from the model by setting $\ell = r = k-m$ allows us to use $m$ additional time periods in estimation and reduces the number of regressors by $m$. 
Stacking over individuals, let $\Delta \mathbf{y} = [\Delta \mathbf{y}'_1 \cdots \Delta \mathbf{y}'_n]'$, $W_\ell = [W_1(\ell) \cdots W_n(\ell)]'$ and define $\Delta \mathbf{y}^{+}$ and $W_\ell^{+}$ analogously, where $\ell$ denotes the lag length used in estimation.
Finally, let $Z'(\ell,\cdot) = [Z'_1(\ell,\cdot) \cdots Z'_n(\ell,\cdot)]$ where $(\cdot)$ is $\text{P}$ or $\text{S}$ depending on the instrument set in use.
Using this notation, under local mis-specification the true model is
\begin{align}
  \Delta \mathbf{y} &= W(k)\beta_n + \Delta \mathbf{v} &  \Delta \mathbf{y}^{+} &= W(k)^{+}\beta_n + \Delta \mathbf{v}^+
\end{align}
Using the shorthand $\widehat{Q} \equiv n[W' Z(Z'Z)^{-1} Z'W]^{-1}W'Z(Z'Z)^{-1}$ our candidate estimators are
\begin{align}
  \widehat{\beta}(k,\cdot) &= \widehat{Q}(k,\cdot)\left[ \frac{Z'(k,\cdot)\Delta \mathbf{y}}{n} \right]& 
  \widehat{\beta}(r,\cdot) &= \widehat{Q}(r,\cdot)\left[ \frac{Z'(r,\cdot)\Delta \mathbf{y}^{+}}{n} \right]
  \label{eq:DpanelEstimators}
\end{align}
where $(\cdot)$ is either $\text{P}$ or $\text{S}$ depending on which instrument set is used and $r = k-m$, $m$ lags fewer than the true lag length $k$.
The following result describes the limit distribution of $\widehat{\beta}(k,\text{P})$, $\widehat{\beta}(k,\text{S})$, $\widehat{\beta}(r,\text{P})$, and $\widehat{\beta}(r,\text{S})$ which we will use to construct the GFIC.

\begin{thm}[Limit Distributions for Dynamic Panel Estimators]
  \label{thm:limitDpanel}
  Let $(y_{nit},x_{nit}, v_{nit})$ be a triangular array of random variables that is iid over $i$, stationary over $t$, and satisfies Equation \ref{eq:truepaneldiff} with $(\gamma_{k-m+1}, \ldots, \gamma_k)' = \boldsymbol{\delta} / \sqrt{n}$.
  Suppose further that $x_{it}$ is predetermined with respect to $v_{it}$ but not strictly exogenous: $E[x_{it}\Delta v_{it}] = \tau/\sqrt{n}$.
  Then, under standard regularity conditions,
  \begin{align*}
    \sqrt{n}\left[ \widehat{\beta}(k,\text{P})-\beta \right] &\rightarrow^d 
    \left[
    \begin{array}{ccc}
    0 & \mathbf{0}_{r}'& \boldsymbol{\delta}'
    \end{array}
  \right]' + 
    Q\left(k,\text{P} \right) \mbox{N}\left(\mathbf{0}, \mathcal{V}(k,\text{P})\right)  \\
    \sqrt{n}\left[ \widehat{\beta}(k,\text{S})-\beta \right] &\rightarrow^d 
    \left[
    \begin{array}{ccc}
    0 & \mathbf{0}_{r}'& \boldsymbol{\delta}'
    \end{array}
  \right]' + 
     Q\left(k,\text{S} \right) \left\{ \boldsymbol{\iota}_{T-(k +1)} \otimes \left[
    \begin{array}{c}
      \mathbf{0}_{k+1} \\ \tau
    \end{array}
  \right] + \mbox{N}\left(\mathbf{0}, \mathcal{V}(k,\text{S})\right)\right\}\\
    \sqrt{n}\left[ \widehat{\beta}(r,\text{P})- \beta_r \right] &\rightarrow^d Q(r,\text{P}) \left[\boldsymbol{\iota}_{T-(r+1)} \otimes  \boldsymbol{\psi}_{\text{P}}\, \boldsymbol{\delta} + \mbox{N}\left(\mathbf{0}, \mathcal{V}(r,\text{P}) \right) \right]\\
    \sqrt{n}\left[ \widehat{\beta}(r,\text{S})- \beta_r\right] &\rightarrow^d Q(r,\text{S}) \left[\boldsymbol{\iota}_{T-(r+1)} \otimes 
    \left(  \left[
  \begin{array}{c}
    \boldsymbol{\psi}_{\text{P}} \\ 
    \boldsymbol{\psi}_{\text{S}} 
\end{array}
\right] \boldsymbol{\delta} + \left[
\begin{array}{c}
  \mathbf{0}_{r+1} \\ \tau
\end{array}
\right]\right) + \mbox{N}\left( \mathbf{0}, \mathcal{V}\left(r,\text{S}\right) \right)\right]
  \end{align*}
  where $r = k - m$, $\beta' = (\theta, \gamma_1, \hdots, \gamma_{r}, \boldsymbol{0}_m')$, $\beta_r' = (\theta, \gamma_1, \hdots, \gamma_{r})$, $\mathcal{V}(k,\cdot) = \mbox{Var}\left[ Z_i(k,\cdot) \Delta \mathbf{v}_i  \right]$, $\mathcal{V}(r,\cdot) = \mbox{Var}\left[ Z_i(r,\cdot) \Delta \mathbf{v}^{+}_i  \right]$, $\widehat{Q}(\ell,\cdot) \rightarrow_p Q(\ell,\cdot)$, $\boldsymbol{\psi}_{\text{P}} = E[\textbf{z}_{it}(r,\text{P}) (\Delta y_{it -(r+1)}, \ldots, \Delta y_{it-k})]$, $\boldsymbol{\psi}_{\text{S}} = E[x_{it} (\Delta y_{it -(r+1)}, \ldots, \Delta y_{it-k})]$, $Z_i(\ell, \cdot)= \mbox{diag}\{\mathbf{z}_{it}'(\ell, \cdot)\}_{t=\ell+2}^T$, $\mathbf{z}_{it}(\ell,\cdot)$ is as in Equation \ref{eq:Zdpanel}, and $\boldsymbol{\iota}_{d}$ denotes a $d$-vector of ones.
\end{thm}

To operationalize the GFIC, we need to provide appropriate estimators of all quantities that appear in Theorem \ref{thm:limitDpanel}.
To estimate ${Q}(k,\text{P})$, ${Q}(k,\text{S})$, ${Q}(r,\text{P})$, and ${Q}(r,\text{S})$ we employ the usual sample analogues $\widehat{Q}(\cdot,\cdot)$ given above, which remain consistent under local mis-specification.
There are many consistent estimators for the variance matrices $\mathcal{V}(k,\text{P})$, $\mathcal{V}(k,\text{S})$, $\mathcal{V}(r,\text{P})$, $\mathcal{V}(r,\text{S})$ under local mis-specification.
In our simulations below, we employ the usual heteroskedasticity-consistent, panel-robust variance matrix estimator.
Because $E[\mathbf{z}_{it}(\ell,\text{S})\Delta v_{it}]\neq 0$, we center our estimators of $\mathcal{V}(\ell, \text{S})$ by subtracting the sample analogue of this expectation when calculating the sample variance.
We estimate $\boldsymbol{\psi}_{\text{P}}$ and $\boldsymbol{\psi}_{\text{S}}$ as follows
\[
  \widehat{\boldsymbol{\psi}}_{\text{P}}' = \frac{1}{nT_k}\begin{bmatrix}
  \sum_{t = k+2}^T \sum_{i = 1}^n \mathbf{z}_{it}(r,\text{P}) \Delta y_{it-(r+1)}\\
  \vdots \\
   \sum_{t = k+2}^T \sum_{i = 1}^n \mathbf{z}_{it}(r,\text{P}) \Delta y_{it-k}
\end{bmatrix},   \quad
\widehat{\boldsymbol{\psi}}_{\text{S}}' = \frac{1}{nT_k}\begin{bmatrix}
   \sum_{t = k+2}^T \sum_{i = 1}^n x_{it} \Delta y_{it-(r+1)}\\
   \vdots\\
    \sum_{t = k+2}^T \sum_{i = 1}^n x_{it} \Delta y_{it-k}
\end{bmatrix}  
\]
where $T_k = T-k-1$.
These estimates use our assumption of stationarity from above.
The only remaining quantities we need to construct the GFIC involve the bias parameters $\boldsymbol{\delta}$ and $\tau$. 
We can read off an asymptotically unbiased estimator of $\boldsymbol{\delta}$ directly from Theorem \ref{thm:limitDpanel}, namely $\widehat{\boldsymbol{\delta}} = \sqrt{n}\; (\widehat{\gamma}_{r+1}(k,\text{P}), \ldots, \widehat{\gamma}_k(k,\text{P}))'$ based on the instrument set that assumes only that $x$ is pre-determined rather than strictly exogenous.
To construct an asymptotically unbiased estimator of $\tau$, we use the residuals from the specification that uses \emph{both} the correct moment conditions and the correct lag specification, specifically
\begin{equation}
  \label{eq:DpanelTau}
  \widehat{\tau} = \left( \frac{\boldsymbol{\iota}_{T-k-1}'}{T - k - 1} \right) n^{-1/2} X' \left[\Delta \mathbf{y} - W(k)\widehat{\beta}(k,\text{P})  \right]
\end{equation}
where $X' = [X_1 \cdots X_n]$ and $X_i = \mbox{diag}\left\{ x_{it} \right\}_{t = k + 2}^{T}$.
The following result gives the joint limiting behavior of $\widehat{\boldsymbol{\delta}}$ and $\widehat{\tau}$, which we will use to construct the GFIC.

\begin{thm}[Joint Limit Distribution of $\widehat{\boldsymbol{\delta}}$ and $\widehat{\tau}$]
  \label{thm:DpanelJoint}
  Under the conditions of Theorem \ref{thm:limitDpanel},
  \[
    \left[
      \begin{array}{c} 
        \widehat{\boldsymbol{\delta}} - \boldsymbol{\delta} \\ \widehat{\tau} - \tau 
      \end{array} 
    \right] \overset{d}{\rightarrow} \Psi \mbox{N}\left(\mathbf{0}, \Pi\,\mathcal{V}\left(k,\text{S}\right)\,\Pi'\right)
  \]
  where $\widehat{\boldsymbol{\delta}} = \sqrt{n}[ \mathbf{e}_k' \,\widehat{\beta}(k,\text{P})]$, $\mathbf{e}_k = (0, \mathbf{0}_{k-m}', \boldsymbol{\iota}_m')'$,  $\widehat{\tau}$ is as defined in Equation \ref{eq:DpanelTau}, 
\[
  \Psi = \left[
  \begin{array}{cc}
    \displaystyle
    \mathbf{e}_k' Q(k,\text{P}) & \mathbf{0}'_{T-k-1}\\
    \left( \frac{\boldsymbol{\iota}'_{T-k-1}}{T-k-1} \right)  \left\{ \boldsymbol{\xi}' Q(k,\text{P}) \otimes \boldsymbol{\iota}'_{T-k-1} \right\}& \displaystyle \left(\frac{\boldsymbol{\iota}_{T-k-1}}{T-k-1}\right) 
  \end{array}
\right],
\]
  $\boldsymbol{\xi}' = E\left\{ x_{it} \left[
    \begin{array}{cccc}
       \Delta x_{it} & L \Delta y_{it} & \cdots & L^k \Delta y_{it}   \end{array} \right]\right\}$,
  the variance matrix $\mathcal{V}(k,\text{S})$ is as defined in Theorem \ref{thm:limitDpanel}, the permutation matrix $\Pi = \left[
  \begin{array}{cc}
    \Pi_1' & \Pi_2'
  \end{array}
\right]'$ with $\Pi_1 = I_{T-k-1} \otimes \left[
\begin{array}{cc}
  I_{k+1} & \mathbf{0}_{k+1}
\end{array}
\right]$ and $\Pi_2 = I_{T-k-1}\otimes \left[
\begin{array}{cc}
  \mathbf{0}_{k+1}' & 1
\end{array}
\right]$,
  $\boldsymbol{\iota}_{d}$ is a $d$-vector of ones and $I_d$ the $(d\times d)$ identity matrix.
\end{thm}

To provide asymptotically unbiased estimators of the quantities $\tau^2$, $\boldsymbol{\delta}\boldsymbol{\delta}'$ and $\boldsymbol{\delta}\tau$ that appear in the AMSE expressions for our estimators, we apply a bias correction to the asymptotically unbiased estimators of $\boldsymbol{\delta}$ and $\tau$ from Theorem \ref{thm:DpanelJoint}.

\begin{cor}
  Let $\widehat{\Psi}$ be a consistent estimator of $\Psi$, defined in Theorem \ref{thm:DpanelJoint}, and $\widehat{\mathcal{V}}(k,\text{S})$ be a consistent estimator of $\mathcal{V}(k,\text{S})$, defined in Theorem \ref{thm:limitDpanel}.
  Then, the elements of  
  \[
    \left[
    \begin{array}{cc}
      \widehat{\boldsymbol{\delta}} \widehat{\boldsymbol{\delta}}' & \widehat{\boldsymbol{\delta}} \widehat{\tau} \\
      \widehat{\tau} \widehat{\boldsymbol{\delta}}' & \widehat{\tau}^2
    \end{array}
  \right] - \widehat{\Psi}\, \Pi \, \widehat{V}(k,\text{S}) \, \Pi' \, \widehat{\Psi}'
  \]
  provide asymptotically unbiased estimators of of $\boldsymbol{\delta}\boldsymbol{\delta}'$, $\tau^2$ and $\boldsymbol{\delta}\tau$, where $\Pi$ is the permutation matrix defined in Theorem \ref{thm:DpanelJoint}.
\end{cor}

We have already discussed consistent estimation of $\widehat{\mathcal{V}}(k,\text{S})$.
Since $\Pi$ is a known permutation matrix, it remains only to propose a consistent estimator of $\Psi$. 
The matrix $\Psi$, in turn, depends only on $Q(k,\text{P})$, and $\boldsymbol{\xi}'$.
The sample analogue $\widehat{Q}(k,\text{P})$ is a consistent estimator for $Q(k,\text{P})$, as mentioned above, and
\begin{equation}
  \widehat{\boldsymbol{\xi}}' = \frac{1}{n(T - k - 1)} \sum_{t = k+2}^T \sum_{i=1}^n x_{it}\left[
  \begin{array}{cccc}
    \Delta x_{it} & L \Delta y_{it} & \cdots & L^{k} \Delta y_{it} 
  \end{array}
\right]
\end{equation}
is consistent for $\xi'$.
We now have all the quantities needed to construct the GFIC for $\mu_{SR}$, the short-run effect of $x$ on $y$.
Since $\mu_{SR} = \theta$, we can read off the AMSE expression for this parameter directly from Theorem \ref{thm:limitDpanel}.
For the long-run effect $\mu_{LR}$, however, we need to formally apply the Delta-method and account for the fact that the true value of $(\gamma_{r+1}, \ldots, \gamma_k)'$ is $\boldsymbol{\delta}/\sqrt{n}$.
Expressed as a function $\varphi$ of the underlying model parameters, 
\[
  \mu_{LR} = \varphi(\theta, \boldsymbol{\gamma}_r, \boldsymbol{\gamma}_{-r}) = \theta / \left[1 - \boldsymbol{\iota}_r' \boldsymbol{\gamma}_r - \boldsymbol{\iota}_m'\boldsymbol{\gamma}_{-r}\right]
\]
where we define $\boldsymbol{\gamma}_{-r} \equiv (\gamma_{r+1}, \ldots, \gamma_k)'$.
The derivatives of $\varphi$ are
\[
  \nabla \varphi \equiv \left[
  \begin{array}{ccc}
    \displaystyle\frac{\partial \varphi}{\partial \theta} & 
    \displaystyle\frac{\partial \varphi}{\partial \boldsymbol{\gamma}_r'} &
    \displaystyle\frac{\partial \varphi}{\partial \boldsymbol{\gamma}_{-r}'} 
  \end{array}
\right] = 
\left( \frac{1}{1 - \boldsymbol{\iota}_r' \boldsymbol{\gamma}_r - \boldsymbol{\iota}_m' \boldsymbol{\gamma}_{-r}} \right)^2 \left[
\begin{array}{ccc}
  \left( 1 - \boldsymbol{\iota}_r' \boldsymbol{\gamma}_r - \boldsymbol{\iota}_m'\boldsymbol{\gamma}_{-r} \right) & \theta \,\boldsymbol{\iota}_r' & \theta \, \boldsymbol{\iota}_m' 
\end{array}
\right].
\]
Using this notation, the limiting value of $\mu_{LR}$ is $\mu_{LR}^{0} =  \varphi(\theta, \boldsymbol{\gamma}_r, \boldsymbol{0}_m')$
while the true value is
$\mu_{LR}^{n} = \varphi(\theta, \boldsymbol{\gamma}_r, \boldsymbol{\delta}/\sqrt{n})$.
Similarly, the limiting value of $\nabla\varphi$ is $\nabla \varphi_0 = \nabla \varphi(\theta, \boldsymbol{\gamma}_r, \boldsymbol{0}_m')'$, obtained by putting zero in place of $\boldsymbol{\gamma}_{-r}$. 
We estimate this quantity consistently by plugging in the estimates from $\widehat{\beta}(k, \text{P})$.

