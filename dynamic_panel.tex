%!TEX root = main.tex
\section{Dynamic Panel Example}
\label{sec:panel}
We now specialize the GFIC to a dynamic panel model of the form 
\begin{equation}
  y_{it} = \gamma_1 y_{it-1} + \cdots + \gamma_p y_{it-p} + \theta x_{it} + \eta_i + v_{it}
  \label{eq:truepanel}
\end{equation}
where $i = 1, \hdots, n$ indexes individuals and $t=1, \hdots, T$  indexes time periods. 
For simplicity, and without loss of generality, we suppose that there are no exogenous time-varying regressors and that all random variables are mean zero.\footnote{Alternatively, we can simply de-mean and project out any time-varying exogenous covariates after taking first-differences.} 
The unobserved error $\eta_i$ is a correlated individual effect: $\sigma_{x\eta}\equiv \mathbb{E}\left[ x_{it}\eta_i \right]$ may not equal zero. 
The endogenous regressor $x_{it}$ is assumed to be predetermined but not necessarily strictly exogenous: $\mathbb{E}[x_{it} v_{is}]=0$ for all $s \geq t$ but may be nonzero for $s < t$.  
We assume throughout that $y_{it}$ is stationary, which requires both $x_{it}$ and $u_{it}$ to be stationary and $|\boldsymbol{\gamma}| < 1$ where $\boldsymbol{\gamma} = (\gamma_1, \dots, \gamma_p)'$.
Our goal is to estimate a given target parameter with minimum MSE: either the short-run effect $\mu_{\text{SR}}$ or the long-run effect $\mu_{\text{LR}}$ of $x$ on $y$, where 
\begin{equation}
  \mu_{\text{SR}} \equiv \theta, \quad \mu_{\text{LR}} \equiv \frac{\theta}{1- (\gamma_1 + \cdots + \gamma_p)}.
  \label{eq:paneltarget}
\end{equation}
The question is which assumptions to use in estimation.
As we discuss below, the answer may depend on whether our target is $\mu_{SR}$ or $\mu_{LR}$.

Our first decision is what assumption to impose on the relationship between $x_{it}$ and $v_{it}$.
This is the \emph{moment selection} decision.
We assumed above that $x$ is predetermined.
Imposing the stronger assumption of strict exogeneity gives us more and stronger moment conditions, but using these in estimation introduces a bias if $x$ is not in fact strictly exogenous.
Our second decision is how many lags of $y$ to use in estimation.
This is the \emph{model selection} decision.
The true model contains $p$ lags of $y$.
If we estimate only $\ell < p$ lags we not only have more degrees of freedom but more observations: every additional lag of $y$ requires us to drop one time period from estimation. 
In the short panel datasets common in microeconomic applications, losing even one additional time period can represent a massive loss of information.
At the same time, unless $\gamma_{\ell+1} = \cdots = \gamma_p = 0$, failing to include all $p$ lags in the model introduces a bias.
In this example, the GFIC simultaneously chooses over exogeneity assumptions for $x$ and lag length for $y$ to optimally trade off bias and variance.

\subsection{Moment Conditions and Estimators}
To eliminate the individual effects $\eta_i$ we work in first differences.
Defining $\Delta$ in the usual way, so that $\Delta y_{it} = y_{it} - y_{it-1}$ and so on, we can write Equation \ref{eq:truepanel} as
\begin{align}
  \Delta y_{it} = \gamma_1 \Delta y_{it-1} + \cdots + \gamma_p \Delta y_{it-p} + \theta \Delta x_{it} + \Delta v_{it}.
  \label{eq:truepaneldiff}
\end{align}
To allow the consideration of models with different lag lengths, some of which may be mis-specified, define the residual
\begin{equation}
  \Delta v_{it}\left(\theta, \boldsymbol{\gamma}_\ell \right) = \Delta y_{it} - \left(\gamma_1 \Delta y_{it-1} + \cdots + \gamma_\ell \Delta y_{it-1} \right) - \theta \Delta x_{it} 
  \label{eq:panelresidual}
\end{equation}
where $\ell$ may not equal $p$ and $\theta$ and $\boldsymbol{\gamma}_\ell$ may not be the true parameter values.
To denote the residual from a model with no lags, $\ell = 0$, we use the shorthand $\Delta v_{it}(\theta) = \Delta y_{it} - \theta \Delta x_{it}$.
For simplicity and to avoid many instruments problems -- see e.g.\ \cite{Roodman} -- we focus here on estimation using the instrument sets
\begin{align}
  \mathbf{z}_{it}(\ell,\text{P}) &\equiv \left[
  \begin{array}{cccc}
    y_{it-2} & \cdots & y_{it-(\ell + 1)} & x_{it-1}
  \end{array}
\right]'
  \label{eq:ZdpanelP}
\\
\mathbf{z}_{it}(\ell, \text{S}) &\equiv \left[
\begin{array}{ccccc}
  y_{it-2} & \cdots & y_{it-(\ell + 1)} & x_{it-1} & x_{it}
\end{array}
\right]'
  \label{eq:ZdpanelS}
\end{align}
similar to \cite{AndersonHsiao}.
Modulo a change in notation, one could just as easily proceed using the instrument sets suggested by \cite{ArellanoBond}.
When $\ell = 0$ we use the shorthand $\mathbf{z}_{it}(\text{P}) = x_{it-1}$ and $\mathbf{z}_{it}(\text{S}) = (x_{it-1}, x_{it})'$.
Using these instruments, estimation of a model with $\ell$ lags is based on the $(\ell + 1)\times T$ moment conditions
\begin{equation}
  E\left[ \mathbf{z}_{it}(\ell,\mbox{P})\Delta v_{it}(\theta, \boldsymbol{\gamma}_\ell) \right] = 0, \quad \mbox{for } t = (\ell + 2),\dots, T
  \label{eq:MCdpanelP}
\end{equation}
if $x$ is only assumed to be predetermined and is based on the $(\ell + 2)\times T$ moment conditions 
\begin{equation}
  E\left[ \mathbf{z}_{it}(\ell,\mbox{S})\Delta v_{it}(\theta, \boldsymbol{\gamma}_\ell) \right] = 0, \quad \mbox{for } t = (\ell + 2),\dots, T 
  \label{eq:MCdpanelS}
\end{equation}
if $x$ is assumed to be strictly exogenous.
To abstract for a moment from the model selection decision, suppose that we estimate a model with the true lag length so that $\Delta v_{it}(\theta, \boldsymbol{\gamma}_p) = \Delta v_{it}$.
The only difference between the P and S sets of moment conditions is that the latter adds over-identifying information in the form of $E[x_{it}\Delta v_{it}]$.
If $x$ is strictly exogenous, this expectation equals zero, but if $x$ is only predetermined, then $E[x_{it}\Delta v_{it}] = -E[x_{it}v_{it-1}] \neq 0$ so the over-identifying moment condition is invalid.
Given the instrument sets that we consider, the only violation of strict exogeneity that is relevant for our moment selection exercise is $E[x_{it}v_{it-1}]\neq 0$.
The crux of our moment selection decision is to trade off the variance reduction that comes from using both $x_{it}$ and $x_{it-1}$ to instrument for $\Delta x_{it}$ against the bias that emerges if $x_{it}$ is correlated with $v_{it-1}$.

In the examples and simulations described below we consider two-stage least squares estimation of $\mu_{SR}$ and $\mu_{LR}$ based on the moment conditions in Equations \ref{eq:MCdpanelP} and \ref{eq:MCdpanelS} using the instruments defined in Equations \ref{eq:ZdpanelP} and \ref{eq:ZdpanelS}.
To define these estimators, we first introduce some additional notation.
First, let $\Delta \mathbf{y}_{i}'(\ell) = [\Delta y_{i,\ell+2}, \cdots, \Delta y_{iT}]$.
Next, for $\ell \geq 1$ define $\mathbf{w}_{it}'(\ell) = [\Delta y_{it-1}, \cdots, \Delta y_{it-\ell}, \Delta x_{it}]$ and let $\mathbf{w}_{it}(0) = \Delta x_{it}$.
Stacking these vectors over $t$, let $W_i(\ell) = [\mathbf{w}_{i\ell+2}(\ell), \hdots, \mathbf{w}_{iT}(\ell)]$.
Now, define the instrument matrices $Z_i(\ell,\mbox{P}) = \mbox{diag}\left\{ \mathbf{z}_{it}'(\ell,\mbox{P}) \right\}_{t=\ell+2}^T$ and $Z_i(\ell,\mbox{S}) = \mbox{diag}\left\{ \mathbf{z}_{it}'(\ell,\mbox{S}) \right\}_{t=\ell+2}^T$.
Finally, stacking over individuals in the usual way, let $\Delta \mathbf{y}'(\ell) = [\Delta \mathbf{y}_1(\ell)', \hdots, \Delta \mathbf{y}_n']$,  $W'(\ell) = [W_1(\ell),\hdots, W_n(\ell)]$, $Z'(\ell,\mbox{P}) = \left[ Z_1'(\ell, \mbox{P}), \hdots, Z_n'(\ell,\mbox{P})\right]$ and $Z'(\ell,\mbox{S}) = \left[ Z_1'(\ell, \mbox{S}), \hdots, Z_n'(\ell,\mbox{S})\right]$.
Using the shorthand
\begin{equation}
  \widehat{K}= \left[ \left( \frac{W'Z}{n} \right)\left( \frac{Z'Z}{n} \right)^{-1}\left( \frac{Z'W}{n} \right)^{-1} \right]\left( \frac{W'Z}{n} \right)\left( \frac{Z'Z}{n} \right)^{-1}
\end{equation}
Using this notation, the TSLS estimator of the full parameter vector $\beta' = (\boldsymbol{\gamma}'_\ell, \theta)$ under a model with $\ell$ lags is
\begin{equation}
  \widehat{\beta}\left( \ell,\cdot \right) = \widehat{K}(\ell, \cdot) \left[ \frac{Z'(\ell,\cdot)\Delta \mathbf{y}(\ell)}{n} \right]
\end{equation}
where $(\ell, \cdot)$ is $(\ell, \mbox{P})$ or $(\ell, \mbox{S})$ depending on which possible instrument set is used in estimation.

\todo[inline]{Presumably the final thing to do in this section, before specializing to particular examples, is to give the limit distribution of an estimator that is based on the correct lag specification versus incorrect, and the correct MCs versus the invalid MCs. Although should probably also give the description of how to estimate $\tau$. Also need to show what we make local to zero: both for the moment and model selection.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Dynamic Panel Example -- OLD VERSION}
\todo[inline]{Have Minsu check that they new, simpler notation indeed leads to the same procedure as the one described using the old notation, preserved in the section for reference.}

\subsection{Models and Moment Conditions}
Our aim is to estimate $\theta$, the effect of a regressor $x_{it}$ on an outcome $y_{it}$, with minimum MSE. The true data generating process is 
	\begin{equation}
				y_{it} = \gamma y_{it-1} + \theta x_{it} + u_{it}
	\end{equation}
where $i = 1, \hdots, n$ indexes individuals and $t=1, \hdots, T$  indexes time periods. We assume stationarity of $x_{it}$ and $u_{it}$ and $|\gamma|<1$ so that $y_{it}$ is stationary. The error term $u_{it}$ follows a one-way error components model
	\begin{equation}
				u_{it}= \eta_i + v_{it}
	\end{equation}
with idiosyncratic component $v_{it}$ and individual effect $\eta_i$. 
The individual effect $\eta_i$ is correlated with $x_{it}$ according to $E[x_it \eta_i]= \sigma_{x\eta}$. 
Under the true DGP, $x_{it}$ is predetermined but may not be strictly exogenous. 
That is, $E[x_{it}v_{is}] = 0$ for all $s\geq t$ but $E[x_{it}v_{is}]$ may be nonzero for $s<t$. 
To remove the correlated individual effects, we take first differences, yielding
	\begin{equation}
	\Delta y_{it} = \gamma \Delta y_{it-1} + \theta \Delta x_{it} + \Delta v_{it}.
	\end{equation}
Under the true data generating process, $x_{it-1}$ and $y_{it-2}$ are both valid instruments for period $t$.
Although $x_{it-1}$ is a strong instrument, using both $x_{it-1}$ and $x_{it}$ to instrument for $\Delta x_{it}$ would be far more efficient. 
Unless $E[x_{it}v_{it-1}]=0$, however, $x_{it}$ is correlated with $\Delta v_{it}$, and including it will bias our estimates. 
Yet if $\sigma_{xv}$ is \emph{nearly} zero, this bias may be small relative to the reduction in variance that including $x_{it}$ provides.  
Our moment selection decision is whether or not to use $x_{it}$ as an instrument for period $t$.

Because we observe only $t = 1, \hdots, T$, estimation in differences with a lagged dependent variable uses information from $T-2$ time periods: $t = 3, \hdots, T$.

In contrast, estimation without a lagged dependent variable uses information from $T-1$ time periods: $t=2, \hdots, T$.
When $T$ is small, as in many micro-data applications, including an unnecessary lagged dependent variable could result in a huge loss in information, substantially increasing the variance of our estimate of $\theta$. 
On the other hand, unless $\gamma$ is zero, failing to include a lagged dependent variable will bias our estimates. 
If $\gamma$ is \emph{nearly} zero, however, this bias may be small compared to the reduction in variance achieved by using an additional time period and estimating one fewer parameter. 
Our model selection decision is whether or not to set $\gamma = 0$.  

Taking these considerations together, we consider four specifications: LW, LS, W, and S. 
Both LW and LS include a lagged dependent variable -- hence the designation ``L'' -- while W and S do not. 
LW and W assume only that $x_{it}$ is predetermined -- hence the designation ``W'' for ``weak exogeneity assumption'' -- while LS and S impose the stronger assumption of \emph{strict} exogeneity. 
Thus, LW and LS estimate the correct model while LW and W use the correct instrument sets. 
The correct specification is LW.

Estimation based on LW uses the $2(T - 2)$ moment conditions
	\begin{equation}
E\left[ \left(\begin{array}{c} y_{i,t-2}\\ x_{i,t-1}
\end{array}\right)\left(\Delta y_{it} - \gamma\Delta y_{i,t-1} -\theta \Delta x_{it}\right)\right] = 0, \mbox{ for } t = 3, \hdots, T
\end{equation}
to which LS adds 
	\begin{equation}
	\label{eq:LSadd}
	E\left[ x_{it}\left(\Delta y_{it} - \gamma\Delta y_{i,t-1} -\theta \Delta x_{it}\right)\right] = 0, \mbox{ for } t = 3, \hdots, T
\end{equation}
for a total of $3(T - 2)$ moment conditions. The additional $T-2$ conditions in Equation \ref{eq:LSadd}, however, may be incorrect: $E[x_{it}\Delta v_{it}] = -E[x_{it}v_{it-1}]$ since $x_{it}$ is only predetermined. Since it is the only violation of strict exogeneity that is relevant for the specifications under consideration, we let $E[x_{it}v_{it-1}] = \sigma_{xv}$. When $\sigma_{xv}\neq 0$, the moment conditions in Equation \ref{eq:LSadd} are mis-specified.


Estimation based on specification W uses the $T-1$ moment conditions
\begin{equation}
E\left[x_{i,t-1} \left(\Delta y_{it} - \theta \Delta x_{it}\right)\right] = 0, \mbox{ for } t = 2, \hdots, T
\end{equation}
to which specification S adds a further $T-1$ moment conditions, namely
\begin{equation}
\label{eq:Sadd}
E\left[x_{it} \left(\Delta y_{it} - \theta \Delta x_{it}\right)\right] = 0, \mbox{ for } t = 2, \hdots, T
\end{equation}
for a total of $2(T - 1)$ conditions. Because specifications W and S use the wrong model, however, these moment conditions are mis-specified:
\begin{equation}
\label{eq:trueexpect}
E\left[\left(\begin{array}{c}x_{i,t-1}\\x_{it}\end{array}\right) \left(\Delta y_{it} - \theta \Delta x_{it}\right)\right] = \left[\begin{array}{c}\gamma E[x_{it-1}\Delta y_{it-1}]\\\gamma E[x_{it}\Delta y_{it-1}] - \sigma_{xv}\end{array} \right]
\end{equation}
which are non-zero unless $\sigma_{xv} = \gamma = 0$.



\subsection{Estimators and Local Mis-specification}

Our aim is to use the GFIC to choose between competing estimators of $\theta$ on the basis of AMSE. 
To do so we must first specify the appropriate form of local mis-specification by analogy with Assumption \ref{assump:local}.
In this example, the parameters $\gamma$ and $\sigma_{xv}$ control the degree of mis-specification present in LS, W and S. 
When $\gamma=0$, both models, with and without a lag, are correctly specified; when $\sigma_{xv}=0$ all instruments under consideration are valid. 
Accordingly, we let $\gamma = \delta/\sqrt{n}$ and $-\sigma_{xv} = \tau/\sqrt{n}$ so that, in the limit, all four specifications are correct. 
In this framework the true parameter vector is $\beta_n = \left(\delta/\sqrt{n}, \theta_0\right)'$ which converges to $\beta_0 = \left(0,\theta_0\right)'$. 

\begin{assump}[Local Mis-specification for Dynamic Panel Example]
\label{assump:localex}
Assume that $\gamma = \delta/\sqrt{n}$ and $-\sigma_{xv} = \tau/\sqrt{n}$ where $\delta$ and $\tau$ are unknown constants.
\end{assump}

To define the estimators corresponding to specifications LW, LS, W and S we first require some additional notation. The symbol ``+'' used as a superscript indicates the inclusion of the extra time period $t=2$ that becomes available when we exclude the lagged dependent variable.
Using this convention, let $\Delta y_i = \left( \Delta y_{i3}, \hdots, \Delta y_{iT} \right)'$ and  $\Delta y_i^+ = \left( \Delta y_{i2},  \hdots, \Delta y_{iT} \right)'$.
Define $\Delta x_i, \Delta x_i^+$ and $\Delta v_i, \Delta v_i^+$ analogously. 
Similarly, let $\Delta y_{i,-1}=\left(\Delta y_{i2}, \hdots, \Delta y_{i,T-1}\right)'$ and $\Delta y_{i,-1}^+=\left(\Delta y_{i1}, \hdots, \Delta y_{i,T-1}\right)'$.
Note that the first element of $\Delta y_{i,-1}^+$ is not observed as $t=1$ is the first available time period. 
Stacking over individuals in the usual way, define $\Delta y = \left( \Delta y_1', \hdots, \Delta y_n'\right)'$  and so on.

The specifications LW and LS share the same model, and hence a design matrix. We denote this as:
	\begin{equation}
	X_L = \left[\begin{array}{cc}  \Delta y_{-1} & \Delta x \end{array}\right]
	\end{equation}
where the subscript $L$ indicates that both of these specifications include a lagged dependent variable.
Similarly, let
\begin{equation}
	X_L^+ = \left[ \begin{array}{cc}\Delta y_{-1}^+ & \Delta x^+ \end{array} \right].
\end{equation}
Although $X_L^+$ is not observed, we use it in the derivations that follow as it allows us to represent the true data generating process in matrix form.
Specifically, 
	\begin{eqnarray}
	\label{eq:DGP}
		\Delta y &=& X_L \beta_n + \Delta v\\
		\label{eq:DGPplus}
		\Delta y^+ &=& X_L^+ \beta_n + \Delta v^+
	\end{eqnarray}

We now turn our attention to the instrument matrices. For ease of notation, define the $(T-k+1)\times 1$ column vector
	\begin{equation}
		\left\{ z_t\right\}_{t=k}^{T} = \left(z_k, z_{k+1}, \hdots, z_{T-1}, z_T \right)'
	\end{equation}
and the $(T-k+1)\times (T-k+1)$ diagonal matrix
\begin{equation}
		D\left\{ z_t \right\}_{t=k}^{T} = \left[\begin{array}{ccc} z_{k} & & 0\\ &\ddots&\\ 0 &&z_T \end{array}\right].
\end{equation}
To construct the instrument matrices, first define the $(T-2)\times(T-2)$ submatrices
\begin{eqnarray}
	Z(y_{i,-2}) &=& D\left\{ y_{i,t-2} \right\}_{t=3}^{T}\\
	Z(x_{i,-1}) &=& D\left\{ x_{i,t-1} \right\}_{t=3}^{T}\\
	\label{eq:Zx}
		Z(x_i) &=& D\left\{x_{it}  \right\}_{t=3}^{T}
 \end{eqnarray}
and the $(T-1)\times(T-1)$ submatrices
\begin{eqnarray}
	Z(x_{i,-1}^+) &=&D\left\{ x_{i,t-1} \right\}_{t=2}^{T}\\
		Z(x_i^+) &=& D\left\{x_{it}  \right\}_{t=2}^{T}.
 \end{eqnarray}
As above, the symbol ``+'' used as a superscript indicates the addition of an additional time period. 
Combining these, define 
	\begin{eqnarray}
	Z_{LS,i} &=& \left(Z(y_{i,-2}), Z(x_{i,-1}), Z(x_i)  \right)'\\
	Z_{LW,i} &=&  \left(Z(y_{i,-2}), Z(x_{i,-1}) \right)'\\
	Z_{S,i} &=& \left(Z(x_{i,-1}^+), Z(x_i^+) \right)'\\
	Z_{W,i} &=& Z(x_{i,-1}^+).
	\end{eqnarray}
Stacking over individuals, let $Z_{LS}' = \left(Z_{LS,1}, \hdots,  Z_{LS,N}\right)$ and so on. 
Finally, define the shorthand
\begin{equation}
\label{eq:K}
	\widehat{K} = \left[\left(\frac{X'Z}{n}\right)\left(\frac{Z'Z}{n}\right)^{-1}\left(\frac{Z'X}{n}\right)\right]^{-1}\left(\frac{X'Z}{n}\right)\left(\frac{Z'Z}{n}\right)^{-1}.
\end{equation}
Using this notation, our four estimators are:
\begin{eqnarray}
	\widehat{\beta}_{LS} &=&  \widehat{K}_{LS}\left(\frac{Z_{LS}'\Delta y}{n}\right)\\
	\widehat{\beta}_{LW} &=& \widehat{K}_{LW}\left(\frac{Z_{LW}'\Delta y}{n}\right)\\
	\widehat{\theta}_{S} &=&  \widehat{K}_S\left(\frac{Z_{S}'\Delta y^+}{n}\right)\\
	\widehat{\theta}_{W} &=&  \widehat{K}_W\left(\frac{Z_{W}'\Delta y^+}{n}\right).
\end{eqnarray}
which can be expanded as 
	\begin{eqnarray}
	\label{eq:distexpandLS}
		\sqrt{n}(\widehat{\beta}_{LS} - \beta_0) = \sqrt{n} \left[\begin{array}{l} \widehat{\gamma}_{LS}\\ \widehat{\theta}_{LS} - \theta_0\end{array}\right]   &=& \left[\begin{array}{c}\delta\\ 0\end{array}\right]+ \widehat{K}_{LS}\left(\frac{Z_{LS}'\Delta v}{n^{1/2}}\right)\\
						\sqrt{n}(\widehat{\beta}_{LW} - \beta_0) = \sqrt{n} \left[\begin{array}{l} \widehat{\gamma}_{LW}\\ \widehat{\theta}_{LW} - \theta_0\end{array}\right]   &=& \left[\begin{array}{c}\delta\\ 0\end{array}\right]+ \widehat{K}_{LW}\left(\frac{Z_{LW}'\Delta v}{n^{1/2}}\right)
\end{eqnarray}
and
\begin{eqnarray}
		\sqrt{n}\left(\widehat{\theta}_S -\theta_0\right)&=& \widehat{K}_S\left[\delta\left( \frac{Z_{S}'\Delta y_{-1}^+}{n}\right) + \left( \frac{Z_{S}'\Delta v^+}{n^{1/2}}\right)\right]\\
		\label{eq:distexpandW}
		\sqrt{n}\left(\widehat{\theta}_W-\theta_0\right) &=&  \widehat{K}_W\left[\delta\left( \frac{Z_{W}'\Delta y_{-1}^+}{n}\right) + \left( \frac{Z_{W}'\Delta v^+}{n^{1/2}}\right)\right]
	\end{eqnarray}
by substituting Equation \ref{eq:DGP}. Combining these expressions with the Lindeberg-Feller central limit theorem and standard regularity conditions gives
	\begin{eqnarray}
		\label{eq:dynpan1}
			\sqrt{n} \left[\begin{array}{l} \widehat{\gamma}_{LS}\\ \widehat{\theta}_{LS} - \theta_0\end{array}\right]   &\overset{d}{\rightarrow}& \left[\begin{array}{c}\delta\\ 0\end{array}\right] +K_{LS} \left\{ \left[\begin{array}{c}0_2\\ \tau \end{array}\right]\otimes \iota_{T-2} + N\left(0, \mathcal{V}_{LS}\right)\right\}\\
			\label{eq:dynpan2}
 			\sqrt{n} \left[\begin{array}{l} \widehat{\gamma}_{LW}\\ \widehat{\theta}_{LW} - \theta_0\end{array}\right]   &\overset{d}{\rightarrow}& \left[\begin{array}{c}\delta\\ 0\end{array}\right] +K_{LW}\; N\left(0, \mathcal{V}_{LW}\right)
	\end{eqnarray}
and
\begin{eqnarray}
\label{eq:dynpan3}
 	\sqrt{n}\left(\widehat{\theta}_{S}-\theta_0\right) &\overset{d}{\rightarrow}&K_S \left[\left(\delta \left[\begin{array}{l} \psi_0\\ \psi_1\end{array} \right] + \left[\begin{array}{c}0\\ \tau \end{array}\right]\right)\otimes \iota_{T-1}+ N\left(0, \mathcal{V}_{S}\right)\right]\\
 	\label{eq:dynpan4}	\sqrt{n}\left(\widehat{\theta}_{W}-\theta_0\right)&\overset{d}{\rightarrow}&K_W  \left[\delta \psi_0 \otimes \iota_{T-1} + N\left(0, \mathcal{V}_W\right) \right].
	\end{eqnarray}
where $K$ denotes the probability limit of $\widehat{K}$ (see Equation \ref{eq:K}) and
	\begin{eqnarray}
		\psi_0 &=&E[x_{it}\Delta y_{it}] \\
		\psi_1 &=&E[x_{it} \Delta y_{it-1}]
	\end{eqnarray}	
with the expectations taken with respect to the limiting DGP, in which all four specifications are correct. 
These expressions immediately yield the AMSE of each estimator of $\theta$. 
To implement the GFIC, we simply estimate the unknowns, as described below.

\subsection{GFIC for the Dynamic Panel Example}
To operationalize the GFIC, we need estimates of the unknowns in Equations \ref{eq:dynpan1}--\ref{eq:dynpan4}.
To estimate $K_{LS}$, $K_{LW}$, $K_W$ and $K_S$ we use $\widehat{K}_{LS}$, $\widehat{K}_{LW}$, $\widehat{K}_W$ and $\widehat{K}_S$, which remain consistent under local mis-specification. 
There are many consistent estimators of the variance matrices $\mathcal{V}_{LS}$, $\mathcal{V}_{LW}$, $\mathcal{V}_{S}$ and $\mathcal{V}_{W}$ under local mis-specification. 
For robustness, we use the centered, panel robust estimator that allows for heteroscedasticity. 
We do not center the estimator for LW because this specification is assumed correct, and this yields a more efficient estimator. 
Using the assumption of stationarity, 
	\begin{eqnarray*}
		\widehat{\psi}_0 &=&\frac{1}{n(T-1)} \sum_{t=2}^T\sum_{i=1}^N x_{it} \Delta y_{it}\\
		\widehat{\psi}_1 &=&\frac{1}{n(T-2)} \sum_{t=3}^T\sum_{i=1}^N x_{it} \Delta y_{it-1}
	\end{eqnarray*}
provide consistent estimators of $\psi_0$ and $\psi_1$.
The only remaining quantities needed to calculate the GFIC involve the bias parameters $\tau$ and $\delta$.
As described above, no consistent estimators of these quantities exist under local mis-specification.
It remains possible, however, to construct asymptotically unbiased estimators.
We can read off an asymptotically unbiased estimator of $\delta$ directly from Equation \ref{eq:dynpan2}, namely $\widehat{\delta} = \sqrt{n}\; \widehat{\gamma}_{LW}$.
To construct an asymptotically unbiased estimator of $\tau$, we define $Z'(x) = \left(Z(x_1), \hdots, Z(x_n)\right)$, see Equation \ref{eq:Zx}, and expand the quantity $n^{-1/2}(\Delta y -X_L\widehat{\beta}_{LW})$ as follows:
$$n^{-1/2}(\Delta y -X_L\widehat{\beta}_{LW}) = \left[\begin{array}{cc} -n^{-1} Z'(x)X_L \widehat{K}_{LW}& I \end{array} \right]n^{-1/2} Z'_{LS}\Delta v$$
Now, by the Lindeberg-Feller Central Limit Theorem (c.f.\ Equation \ref{eq:dynpan1}) we have
$$n^{-1/2} Z'_{LS}\Delta v \overset{d}{\rightarrow}\left[\begin{array}{c}0_2\\ \tau \end{array}\right]\otimes \iota_{T-2} + N\left(0, \mathcal{V}_{LS}\right)$$
and by a Law of Large Numbers,
	$$n^{-1}Z'(x)X_L \overset{p}{\rightarrow} E\left[\begin{array}{cc} x_{it}\Delta y_{it-1} & x_{it}\Delta x_{it}\end{array} \right]\otimes \iota_{T-2}$$
where the expectations are taken with respect to the limiting DGP. 
Thus,
	\begin{equation}
		n^{-1/2}(\Delta y -X_L\widehat{\beta}_{LW}) \overset{d}{\rightarrow} \tau \otimes \iota_{T-2} + \left[ \begin{array}{cc} \Psi & I\end{array}\right] N(0, \mathcal{V}_{LS})
	\end{equation}
where
\begin{equation}
	\Psi = -E\left[\begin{array}{cc} x_{it}\Delta y_{it-1} & x_{it}\Delta x_{it}\end{array} \right]\otimes \iota_{T-2} K_{LW}
\end{equation}
Using stationarity to gain efficiency we take the time average
\begin{equation}
\widetilde{\tau} =  \left(\frac{\iota'_{T-2}}{T-2} \right)n^{-1/2} Z'(x)(\Delta y - X_L \widehat{\beta}_{LW})
\end{equation}
as our estimator of $\tau$. 
It follows from above that
\begin{equation}
	\widetilde{\tau} \overset{d}{\rightarrow} \tau + \left(\frac{\iota'_{T-2}}{T-2} \right)\left[ \begin{array}{cc} \Psi & I\end{array}\right] N(0, \mathcal{V}_{LS})
\end{equation}
As describe above for the general GMM case, asymptotically unbiased estimators of $\tau$ and $\delta$ require a bias correction to provide asymptotically unbiased estimators of the quantities $\tau^2$, $\delta^2$ and $\tau\delta$ needed to estimate AMSE. 
To carry out this correction, we use the joint distribution of the bias parameter estimators:
	\begin{equation}
	 \left[\begin{array}{c} \widehat{\delta} \\ \widetilde{\tau}  \end{array} \right] \overset{d}{\rightarrow} \left[\begin{array}{c} \widehat{\delta} \\ \widetilde{\tau}  \end{array} \right]  + \left[\begin{array}{cc} K_{LW}^\gamma&0 \\ \left(\frac{\iota'_{T-2}}{T-2} \right) \Psi&  \left(\frac{\iota'_{T-2}}{T-2} \right) I\end{array} \right] N(0, \mathcal{V}_{LS})
	\end{equation}
where $K_{LW}^\gamma$ denotes the first row of $K_{LW}$ (i.e.\ the row corresponding to $\gamma$).
Asymptotically unbiased estimators of $\delta^2$, $\tau^2$ and $\tau\delta$ are given by
\begin{eqnarray}
	\delta^2 \colon &&\widehat{\delta}^2 - \widehat{\sigma}_\delta^2\\
	\tau^2 \colon &&\widetilde{\tau}^2 - \widehat{\sigma}_\tau^2\\
	\tau \delta \colon && \widetilde{\tau}\widehat{\delta} - \widehat{\sigma}_{\tau\delta}
\end{eqnarray}
where $\widehat{\sigma}_\delta^2$, $\widehat{\sigma}_\tau^2$ and $\widehat{\sigma}_{\tau\delta}$ are consistent estimators of the elements of
$$\left[\begin{array}{cc} K_{LW}^\gamma&0 \\ \left(\frac{\iota'_{T-2}}{T-2} \right) \Psi&  \left(\frac{\iota'_{T-2}}{T-2} \right) I\end{array} \right] \mathcal{V}_{LS}  \left[\begin{array}{cc} K_{LW}^\gamma&0 \\ \left(\frac{\iota'_{T-2}}{T-2} \right) \Psi&  \left(\frac{\iota'_{T-2}}{T-2} \right) I\end{array} \right]'$$
We have already described how to consistently estimate $K_{LW}$ and $\mathcal{V}_{LS}$ above, so the only quantities for which we still require consistent estimators are 
	\begin{eqnarray}
		\omega_1 &=& E[x_{it}\Delta y_{it-1}]\\
		 \omega_2 &=& E[x_{it}\Delta x_{it}]
	\end{eqnarray}
which appear in the expression for $\Psi$.
Under stationarity, the following estimators are consistent:
		\begin{eqnarray}
		\widehat{\omega}_1 &=& \frac{1}{n(T-2)}\sum_{t=3}^T \sum_{i=1}^n x_{it}\Delta y_{it-1}\\
		 \widehat{\omega}_2 &=&\frac{1}{n(T-1)}\sum_{t=2}^T \sum_{i=1}^n x_{it}\Delta x_{it}
	\end{eqnarray}
Substituting these estimators into the AMSE expressions implied by Equations \ref{eq:dynpan1}--\ref{eq:dynpan4} yields the GFIC.
	

