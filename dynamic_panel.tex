%!TEX root = main.tex
\section{Dynamic Panel Example}
\label{sec:panel}
We now specialize the GFIC to a dynamic panel model of the form 
\begin{equation}
  y_{it} = \gamma_1 y_{it-1} + \cdots + \gamma_k y_{it-k} + \theta x_{it} + \eta_i + v_{it}
  \label{eq:truepanel}
\end{equation}
where $i = 1, \hdots, n$ indexes individuals and $t=1, \hdots, T$  indexes time periods. 
For simplicity, and without loss of generality, we suppose that there are no exogenous time-varying regressors and that all random variables are mean zero.\footnote{Alternatively, we can simply de-mean and project out any time-varying exogenous covariates after taking first-differences.} 
The unobserved error $\eta_i$ is a correlated individual effect: $\sigma_{x\eta}\equiv \mathbb{E}\left[ x_{it}\eta_i \right]$ may not equal zero. 
The endogenous regressor $x_{it}$ is assumed to be predetermined but not necessarily strictly exogenous: $\mathbb{E}[x_{it} v_{is}]=0$ for all $s \geq t$ but may be nonzero for $s < t$.  
We assume throughout that $y_{it}$ is stationary, which requires both $x_{it}$ and $u_{it}$ to be stationary and $|\boldsymbol{\gamma}| < 1$ where $\boldsymbol{\gamma} = (\gamma_1, \dots, \gamma_k)'$.
Our goal is to estimate a given one of the following two target parameters with minimum MSE:
\begin{equation}
  \mu_{\text{SR}} \equiv \theta, \quad \mu_{\text{LR}} \equiv \frac{\theta}{1- (\gamma_1 + \cdots + \gamma_k)}.
  \label{eq:paneltarget}
\end{equation}
where $\mu_{\text{SR}}$ denotes the short-run effect and $\mu_{\text{LR}}$ the long-run effect of $x$ on $y$.

The question is which assumptions to use in estimation.
Naturally, the answer may depend on whether our target is $\mu_{SR}$ or $\mu_{LR}$.
Our first decision is what assumption to impose on the relationship between $x_{it}$ and $v_{it}$.
This is the \emph{moment selection} decision.
We assumed above that $x$ is predetermined.
Imposing the stronger assumption of strict exogeneity gives us more and stronger moment conditions, but using these in estimation introduces a bias if $x$ is not in fact strictly exogenous.
Our second decision is how many lags of $y$ to use in estimation.
This is the \emph{model selection} decision.
The true model contains $k$ lags of $y$.
If we estimate only $r < k$ lags we not only have more degrees of freedom but more observations: every additional lag of $y$ requires us to drop one time period from estimation. 
In the short panel datasets common in microeconomic applications, losing even one additional time period can represent a substantial loss of information.
At the same time, unless $\gamma_{r+1} = \cdots = \gamma_k = 0$, failing to include all $k$ lags in the model introduces a bias.
%In this example, the GFIC simultaneously chooses over exogeneity assumptions for $x$ and lag length for $y$ to optimally trade off bias and variance.

To eliminate the individual effects $\eta_i$ we work in first differences.
Defining $\Delta$ in the usual way, so that $\Delta y_{it} = y_{it} - y_{it-1}$ and so on, we can write Equation \ref{eq:truepanel} as
\begin{align}
  \Delta y_{it} = \gamma_1 \Delta y_{it-1} + \cdots + \gamma_k \Delta y_{it-k} + \theta \Delta x_{it} + \Delta v_{it}.
  \label{eq:truepaneldiff}
\end{align}
For simplicity and to avoid many instruments problems -- see e.g.\ \cite{Roodman} -- we focus here on estimation using the instrument sets
\begin{align}
  \mathbf{z}'_{it}(\ell, \text{P}) &\equiv \left[
  \begin{array}{cccc}
    y_{it-2} & \cdots & y_{it-(\ell + 1)} & x_{it-1}
  \end{array}
\right] & 
\mathbf{z}'_{it}(\ell,\text{S}) &\equiv \left[
\begin{array}{cc}
  \mathbf{z}_{it}'(\ell,\text{P}) & x_{it}
\end{array}
\right]
\label{eq:Zdpanel}
\end{align}
similar to \cite{AndersonHsiao}.\footnote{Modulo a change in notation, one could just as easily proceed using the instrument sets suggested by \cite{ArellanoBond}.}
Throughout this discussion we use $\ell$ as a placeholder for the lag length used in estimation.
If $\ell = 0$, $\mathbf{z}'_{it}(0,\text{P}) = x_{it-1}$ and $\mathbf{z}'_{it}(0,\text{S}) = (x_{it-1}, x_{it})$.
Given these instrument sets, we have $(\ell + 1)\times (T -\ell - 1)$ moment conditions if $x$ is assumed to be predetermined versus $(\ell + 2)\times (T - \ell - 1)$ if it is assumed to be strictly exogenous, corresponding to the instrument matrices
  $Z_i(\ell,\text{P}) = \mbox{diag}\left\{ \mathbf{z}'_{it}(\ell,\text{P})  \right\}_{t = \ell + 2}^T$ and  $Z_i(\ell,\text{S}) = \mbox{diag}\left\{\mathbf{z}'_{it}(\ell,\text{S}) \right\}_{t = \ell +2}^T$.
To abstract for a moment from the model selection decision, suppose that we estimate a model with the true lag length: $\ell = k$.
The only difference between the P and S sets of moment conditions is that the latter adds over-identifying information in the form of $E[x_{it}\Delta v_{it}]$.
If $x$ is strictly exogenous, this expectation equals zero, but if $x$ is only predetermined, then $E[x_{it}\Delta v_{it}] = -E[x_{it}v_{it-1}] \neq 0$ so the over-identifying moment condition is invalid.
Given the instrument sets that we consider, this is the only violation of strict exogeneity that is relevant for our moment selection so we take $-E[x_{it}v_{it-1}] = \tau/\sqrt{n}$.

In the examples and simulations described below we consider two-stage least squares (TSLS) estimation of $\mu_{SR}$ and $\mu_{LR}$ using the instruments defined in Equation \ref{eq:Zdpanel}. 
For simplicity, we select between two lag length specifications: one of which is correct, $\ell = k$, and one of includes one lag too few: $\ell = r$ where $r = k-1$.
Accordingly, we make coefficient associated with the $k$\textsuperscript{th} lag local to zero.
Let $\boldsymbol{\gamma}' = (\gamma_1, \cdots, \gamma_{k-1}, \gamma_{k})$ denote the full vector of lag coefficients that $\boldsymbol{\gamma}_{r} = (\gamma_1, \cdots, \gamma_{r})$ the first $r = k-1$ lag coefficients.
Then, the true parameter vector is $\beta_n = (\boldsymbol{\gamma}'_{r}, \delta/\sqrt{n}, \theta)'$ which becomes, in the limit, $\beta = (\boldsymbol{\gamma}'_r, 0, \theta)'$.
To indicate the subvector of $\beta$ that excludes the $k$\textsuperscript{th} lag coefficient, let $\beta_{r} = (\boldsymbol{\gamma}_r', \theta)'$.

Because the two lag specifications we consider use different time periods in estimation, we require some additional notation to make this clear. 
First let
$\Delta \mathbf{y}_{i} = [\Delta y_{i,k+2}, \cdots, \Delta y_{iT}]'$ and $\Delta \mathbf{y}^+_{i} = [\Delta y_{i,k+1}, \Delta y_{i,k+2}, \cdots, \Delta y_{iT}]'$ 
where the superscript ``+'' indicates the inclusion of an additional time period: $t = k+1$.
Define $\Delta \mathbf{x}_i$, $\Delta \mathbf{x}_{i}^{+}$, $\Delta \mathbf{v}_i$, and $\Delta \mathbf{v}_{i}^{+}$ analogously.
Next, define $L^k\Delta \mathbf{y}_i^{+} = [\Delta y_{i1}, \Delta y_{i2}, \cdots, \Delta y_{iT-k}]'$ where $L^k$ denotes the element-wise application of the $k$\textsuperscript{th} order lag operator.
Note that the first element of $L^k\Delta \mathbf{y}_{i}^{+}$ is unobserved since $\Delta y_{i1} = y_{i1} - y_{i0}$ but $t=1$ is the first time period.
Now we define the matrices of regressors for the two specifications: $\ell = k$ and $\ell = r$:
\begin{align*}
  W_i^{+'}(r) &= \left[
  \begin{array}{ccccc}
    L \Delta \mathbf{y}_i^{+} &  L^2 \Delta \mathbf{y}_i^{+} & \cdots & L^{k-1}\Delta \mathbf{y}_i^{+} & \Delta \mathbf{x}_i^+
  \end{array}
\right]\\
  W_i'(k) &= \left[
  \begin{array}{cccccc}
    L \Delta \mathbf{y}_i &  L^2 \Delta \mathbf{y}_i & \cdots & L^{k-1}\Delta \mathbf{y}_i & L^k\Delta \mathbf{y}_i & \Delta \mathbf{x}_i
  \end{array}
\right].
\end{align*}
Note that $W_i^{+}(r)$ contains one more row than $W_i(k)$ but $W_i(k)$ contains one more column that $W_i^{+}(r)$: removing the $k$\textsuperscript{th} lag from the model by setting $\ell = r = k-1$ allows us to use an additional time period in estimation and reduces the number of regressors by one. 
Stacking over individuals, let $\Delta \mathbf{y} = [\Delta \mathbf{y}'_1 \cdots \Delta \mathbf{y}'_n]'$, $W_\ell = [W_1(\ell) \cdots W_n(\ell)]'$ and define $\Delta \mathbf{y}^{+}$ and $W_\ell^{+}$ analogously, where $\ell$ denotes the lag length used in estimation.
Finally, let $Z'(\ell,\cdot) = [Z'_1(\ell,\cdot) \cdots Z'_n(\ell,\cdot)]$ where $(\cdot)$ is $\text{P}$ or $\text{S}$ depending on the instrument set is in use.
Using this notation, under local mis-specification the true model is
\begin{align}
  \Delta \mathbf{y} &= W(k)\beta_n + \Delta \mathbf{v} &  \Delta \mathbf{y}^{+} &= W(k)^{+}\beta_n + \Delta \mathbf{v}^+
\end{align}
Using the shorthand $\widehat{Q} \equiv n[W' Z(Z'Z)^{-1} Z'W]^{-1}W'Z(Z'Z)^{-1}$ our candidate estimators are
\begin{align}
  \widehat{\beta}(k,\cdot) &= \widehat{Q}(k,\cdot)\left[ \frac{Z'(k,\text{S})\Delta \mathbf{y}}{n} \right]& 
  \widehat{\beta}(r,\cdot) &= \widehat{Q}(r,\cdot)\left[ \frac{Z'(r,\text{S})\Delta \mathbf{y}^{+}}{n} \right]
\end{align}
where $(\cdot)$ is either $\text{P}$ or $\text{S}$ depending on which instrument set is used and $r = k-1$, one lag fewer than the true lag length $k$.
The following result describes the limit distribution of $\widehat{\beta}(k,\text{P})$, $\widehat{\beta}(k,\text{S})$, $\widehat{\beta}(r,\text{P})$, and $\widehat{\beta}(r,\text{P})$ which we will use to construct the GFIC.

\begin{thm}[Limit Distributions for Dynamic Panel Estimators]
  \label{thm:limitDpanel}
  Let $(y_{nit},x_{nit}, v_{nit})$ be a triangular array of random variables that is iid over $i$, stationary over $t$, and satisfies Equation \ref{eq:truepaneldiff} with $\gamma_k = \delta / \sqrt{n}$.
  Suppose further that $x_{it}$ is predetermined with respect to $v_{it}$ but not strictly exogenous: $E[x_{it}\Delta v_{it}] = \tau/\sqrt{n}$.
  Then, under standard regularity conditions,
  \begin{align*}
    \sqrt{n}\left[ \widehat{\beta}(k,\text{P})-\beta \right] &\rightarrow^d 
    \left[
    \begin{array}{ccc}
    \mathbf{0}_{k-1}'& \delta & 0
    \end{array}
  \right]' + 
    Q\left(k,\text{P} \right) \mbox{N}\left(\mathbf{0}, \mathcal{V}(k,\text{P})\right)  \\
    \sqrt{n}\left[ \widehat{\beta}(k,\text{S})-\beta \right] &\rightarrow^d 
    \left[
    \begin{array}{ccc}
    \mathbf{0}_{k-1}'& \delta & 0
    \end{array}
  \right]' + 
     Q\left(k,\text{S} \right) \left\{ \boldsymbol{\iota}_{T-(k +1)} \otimes \left[
    \begin{array}{c}
      \mathbf{0}_{k+1} \\ \tau
    \end{array}
  \right] + \mbox{N}\left(\mathbf{0}, \mathcal{V}(k,\text{S})\right)\right\}\\
    \sqrt{n}\left[ \widehat{\beta}(r,\text{P})- \beta_r \right] &\rightarrow^d Q(r,\text{P}) \left[\boldsymbol{\iota}_{T-k} \otimes \delta \boldsymbol{\psi}_{\text{P}} + \mbox{N}\left(\mathbf{0}, \mathcal{V}(r,\text{P}) \right) \right]\\
    \sqrt{n}\left[ \widehat{\beta}(r,\text{S})- \beta_r\right] &\rightarrow^d Q(r,\text{S}) \left[\boldsymbol{\iota}_{T-k} \otimes 
    \left( \delta \left[
  \begin{array}{c}
    \boldsymbol{\psi}_{\text{P}} \\ \psi_{\text{S}}
\end{array}
\right] + \left[
\begin{array}{c}
  \mathbf{0}_{k} \\ \tau
\end{array}
\right]\right) + \mbox{N}\left( \mathbf{0}, \mathcal{V}\left(r,\text{S}\right) \right)\right]
  \end{align*}
  where $k = r - 1$, $\beta' = (\gamma_1, \hdots, \gamma_{r}, 0, \theta)$, $\beta_r' = (\gamma_1, \hdots, \gamma_{r}, \theta)$, $\mathcal{V}(k,\cdot) = \mbox{Var}\left[ Z_i(k,\cdot) \Delta \mathbf{v}_i  \right]$, $\mathcal{V}(r,\cdot) = \mbox{Var}\left[ Z_i(r,\cdot) \Delta \mathbf{v}^{+}_i  \right]$, $\widehat{Q}(\ell,\cdot) \rightarrow_p Q(\ell,\cdot)$, $\boldsymbol{\psi}_{\text{P}} = E[\textbf{z}_{it}(r,\text{P}) \Delta y_{it -k}]$, $\psi_{\text{S}} = E[x_{it} \Delta y_{it-k}]$, and $\boldsymbol{\iota}_{d}$ denotes a $d$-vector of ones.
\end{thm}

To operationalize the GFIC, we need to provide appropriate estimators of all quantities that appear in Theorem \ref{thm:limitDpanel}.
To estimate ${Q}(k,\text{P})$, ${Q}(k,\text{S})$, ${Q}(k,\text{P})$, and ${Q}(r,\text{S})$ we employ the usual sample analogues $\widehat{Q}(\cdot,\cdot)$ given above, which remain consistent under local mis-specification.
There are many consistent estimators for the variance matrices $\mathcal{V}(k,\text{P})$, $\mathcal{V}(k,\text{S})$, $\mathcal{V}(r,\text{P})$, $\mathcal{V}(r,\text{S})$ under local mis-specification.
In our simulations and empirical example below, we employ the usual heteroskedasticity-consistent, panel-robust variance matrix estimator.
Because $E[\mathbf{z}_{it}(\ell,\text{S})\Delta v_{it}]\neq 0$, we center our estimators of $\mathcal{V}(\ell, \text{S})$ by subtracting the sample analogue of this expectation when calculating the sample variance.
We estimate $\boldsymbol{\psi}_{\text{P}}$ and $\psi_{\text{S}}$ as follows
\begin{align*}
  \widehat{\boldsymbol{\psi}}_{\text{P}} &= \frac{1}{n(T - k - 1)}\sum_{t = k+2}^T \sum_{i = 1}^n \mathbf{z}_{it}(r,\text{P}) \Delta y_{it-k} &
  \widehat{\psi}_{\text{S}} &= \frac{1}{n(T - k - 1)}\sum_{t = k+2}^T \sum_{i = 1}^n x_{it} \Delta y_{it-k}
\end{align*}
using our assumption of stationarity from above.
The only remaining quantities we need to construct the GFIC involve the bias parameters $\delta$ and $\tau$. 
We can read off an asymptotically unbiased estimator of $\delta$ directly from Theorem \ref{thm:limitDpanel}, namely $\widehat{\delta} = \sqrt{n}\; \widehat{\gamma}_k(k,\text{P})$ the estimator of $\gamma_k$ based on the instrument set that assumes only that $x$ is pre-determined rather than strictly exogenous.
To construct an asymptotically unbiased estimator of $\tau$, we use the residuals from the specification that uses \emph{both} the correct moment conditions and the correct lag specification, specifically
\begin{equation}
  \widehat{\tau} = \left( \frac{\boldsymbol{\iota}_{T-k-1}'}{T - k - 1} \right) n^{-1/2} X' \left[\Delta \mathbf{y} - W(k)  \right]
\end{equation}
where $X' = [X_1 \cdots X_n]$ and $X_i = \mbox{diag}\left\{ x_{it} \right\}_{t = k + 2}^{T}$.
The following result gives the joint limiting behavior of $\widehat{\delta}$ and $\widehat{\tau}$, which we will use to construct the GFIC.

\begin{thm}[Joint Limit Distribution of $(\widehat{\delta},\widehat{\tau})$]
  Under blah blah blah assumptions.
	\begin{equation}
	 \left[\begin{array}{c} \widehat{\delta} \\ \widehat{\tau}  \end{array} \right] \overset{d}{\rightarrow} \left[\begin{array}{c} \widehat{\delta} \\ \widehat{\tau}  \end{array} \right]  + \left[\begin{array}{cc} K_{LW}^\gamma&0 \\ \left(\frac{\iota'_{T-2}}{T-2} \right) \Psi&  \left(\frac{\iota'_{T-2}}{T-2} \right) I\end{array} \right] N(0, \mathcal{V}_{LS})
	\end{equation}
  where $K_{LW}^\gamma$ denotes the first row of $K_{LW}$ (i.e.\ the row corresponding to $\gamma$) and also define $\widehat{\tau}$ and $\widehat{\delta}$ and fix the rest of the notation to be general.
\end{thm}

\begin{proof}
define $Z'(x) = \left(Z(x_1), \hdots, Z(x_n)\right)$, see Equation \ref{eq:Zx}, and expand the quantity $n^{-1/2}(\Delta y -X_L\widehat{\beta}_{LW})$ as follows:
$$n^{-1/2}(\Delta y -X_L\widehat{\beta}_{LW}) = \left[\begin{array}{cc} -n^{-1} Z'(x)X_L \widehat{K}_{LW}& I \end{array} \right]n^{-1/2} Z'_{LS}\Delta v$$
Now, by the Lindeberg-Feller Central Limit Theorem (c.f.\ Equation \ref{eq:dynpan1}) we have
$$n^{-1/2} Z'_{LS}\Delta v \overset{d}{\rightarrow}\left[\begin{array}{c}0_2\\ \tau \end{array}\right]\otimes \iota_{T-2} + N\left(0, \mathcal{V}_{LS}\right)$$
and by a Law of Large Numbers,
	$$n^{-1}Z'(x)X_L \overset{p}{\rightarrow} E\left[\begin{array}{cc} x_{it}\Delta y_{it-1} & x_{it}\Delta x_{it}\end{array} \right]\otimes \iota_{T-2}$$
where the expectations are taken with respect to the limiting DGP. 
Thus,
	\begin{equation}
		n^{-1/2}(\Delta y -X_L\widehat{\beta}_{LW}) \overset{d}{\rightarrow} \tau \otimes \iota_{T-2} + \left[ \begin{array}{cc} \Psi & I\end{array}\right] N(0, \mathcal{V}_{LS})
	\end{equation}
where
\begin{equation}
	\Psi = -E\left[\begin{array}{cc} x_{it}\Delta y_{it-1} & x_{it}\Delta x_{it}\end{array} \right]\otimes \iota_{T-2} K_{LW}
\end{equation}
Using stationarity to gain efficiency we take the time average
\begin{equation}
\widetilde{\tau} =  \left(\frac{\iota'_{T-2}}{T-2} \right)n^{-1/2} Z'(x)(\Delta y - X_L \widehat{\beta}_{LW})
\end{equation}
as our estimator of $\tau$. 
It follows from above that
\begin{equation}
	\widetilde{\tau} \overset{d}{\rightarrow} \tau + \left(\frac{\iota'_{T-2}}{T-2} \right)\left[ \begin{array}{cc} \Psi & I\end{array}\right] N(0, \mathcal{V}_{LS})
\end{equation}
\end{proof}
As described above for the general GMM case, asymptotically unbiased estimators of $\tau$ and $\delta$ require a bias correction to provide asymptotically unbiased estimators of the quantities $\tau^2$, $\delta^2$ and $\tau\delta$ needed to estimate AMSE. 
To carry out this correction, we use the joint distribution of the bias parameter estimators:
\begin{cor}[Asymptotically Unbiased Estimators]
Asymptotically unbiased estimators of $\delta^2$, $\tau^2$ and $\tau\delta$ are given by
\begin{eqnarray}
	\delta^2 \colon &&\widehat{\delta}^2 - \widehat{\sigma}_\delta^2\\
	\tau^2 \colon &&\widetilde{\tau}^2 - \widehat{\sigma}_\tau^2\\
	\tau \delta \colon && \widetilde{\tau}\widehat{\delta} - \widehat{\sigma}_{\tau\delta}
\end{eqnarray}
where $\widehat{\sigma}_\delta^2$, $\widehat{\sigma}_\tau^2$ and $\widehat{\sigma}_{\tau\delta}$ are consistent estimators of the elements of
$$\left[\begin{array}{cc} K_{LW}^\gamma&0 \\ \left(\frac{\iota'_{T-2}}{T-2} \right) \Psi&  \left(\frac{\iota'_{T-2}}{T-2} \right) I\end{array} \right] \mathcal{V}_{LS}  \left[\begin{array}{cc} K_{LW}^\gamma&0 \\ \left(\frac{\iota'_{T-2}}{T-2} \right) \Psi&  \left(\frac{\iota'_{T-2}}{T-2} \right) I\end{array} \right]'$$
\end{cor}

\todo[inline]{Also need to explain about the derivatives needed when we want to apply the GFIC to the estimator for the long-run effect}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Dynamic Panel Example -- OLD VERSION}
\todo[inline]{Have Minsu check that they new, simpler notation indeed leads to the same procedure as the one described using the old notation, preserved in the section for reference.}

\subsection{Models and Moment Conditions}
Our aim is to estimate $\theta$, the effect of a regressor $x_{it}$ on an outcome $y_{it}$, with minimum MSE. The true data generating process is 
	\begin{equation}
				y_{it} = \gamma y_{it-1} + \theta x_{it} + u_{it}
	\end{equation}
where $i = 1, \hdots, n$ indexes individuals and $t=1, \hdots, T$  indexes time periods. We assume stationarity of $x_{it}$ and $u_{it}$ and $|\gamma|<1$ so that $y_{it}$ is stationary. The error term $u_{it}$ follows a one-way error components model
	\begin{equation}
				u_{it}= \eta_i + v_{it}
	\end{equation}
with idiosyncratic component $v_{it}$ and individual effect $\eta_i$. 
The individual effect $\eta_i$ is correlated with $x_{it}$ according to $E[x_it \eta_i]= \sigma_{x\eta}$. 
Under the true DGP, $x_{it}$ is predetermined but may not be strictly exogenous. 
That is, $E[x_{it}v_{is}] = 0$ for all $s\geq t$ but $E[x_{it}v_{is}]$ may be nonzero for $s<t$. 
To remove the correlated individual effects, we take first differences, yielding
	\begin{equation}
	\Delta y_{it} = \gamma \Delta y_{it-1} + \theta \Delta x_{it} + \Delta v_{it}.
	\end{equation}
Under the true data generating process, $x_{it-1}$ and $y_{it-2}$ are both valid instruments for period $t$.
Although $x_{it-1}$ is a strong instrument, using both $x_{it-1}$ and $x_{it}$ to instrument for $\Delta x_{it}$ would be far more efficient. 
Unless $E[x_{it}v_{it-1}]=0$, however, $x_{it}$ is correlated with $\Delta v_{it}$, and including it will bias our estimates. 
Yet if $\sigma_{xv}$ is \emph{nearly} zero, this bias may be small relative to the reduction in variance that including $x_{it}$ provides.  
Our moment selection decision is whether or not to use $x_{it}$ as an instrument for period $t$.

Because we observe only $t = 1, \hdots, T$, estimation in differences with a lagged dependent variable uses information from $T-2$ time periods: $t = 3, \hdots, T$.

In contrast, estimation without a lagged dependent variable uses information from $T-1$ time periods: $t=2, \hdots, T$.
When $T$ is small, as in many micro-data applications, including an unnecessary lagged dependent variable could result in a huge loss in information, substantially increasing the variance of our estimate of $\theta$. 
On the other hand, unless $\gamma$ is zero, failing to include a lagged dependent variable will bias our estimates. 
If $\gamma$ is \emph{nearly} zero, however, this bias may be small compared to the reduction in variance achieved by using an additional time period and estimating one fewer parameter. 
Our model selection decision is whether or not to set $\gamma = 0$.  

Taking these considerations together, we consider four specifications: LW, LS, W, and S. 
Both LW and LS include a lagged dependent variable -- hence the designation ``L'' -- while W and S do not. 
LW and W assume only that $x_{it}$ is predetermined -- hence the designation ``W'' for ``weak exogeneity assumption'' -- while LS and S impose the stronger assumption of \emph{strict} exogeneity. 
Thus, LW and LS estimate the correct model while LW and W use the correct instrument sets. 
The correct specification is LW.

Estimation based on LW uses the $2(T - 2)$ moment conditions
	\begin{equation}
E\left[ \left(\begin{array}{c} y_{i,t-2}\\ x_{i,t-1}
\end{array}\right)\left(\Delta y_{it} - \gamma\Delta y_{i,t-1} -\theta \Delta x_{it}\right)\right] = 0, \mbox{ for } t = 3, \hdots, T
\end{equation}
to which LS adds 
	\begin{equation}
	\label{eq:LSadd}
	E\left[ x_{it}\left(\Delta y_{it} - \gamma\Delta y_{i,t-1} -\theta \Delta x_{it}\right)\right] = 0, \mbox{ for } t = 3, \hdots, T
\end{equation}
for a total of $3(T - 2)$ moment conditions. The additional $T-2$ conditions in Equation \ref{eq:LSadd}, however, may be incorrect: $E[x_{it}\Delta v_{it}] = -E[x_{it}v_{it-1}]$ since $x_{it}$ is only predetermined. Since it is the only violation of strict exogeneity that is relevant for the specifications under consideration, we let $E[x_{it}v_{it-1}] = \sigma_{xv}$. When $\sigma_{xv}\neq 0$, the moment conditions in Equation \ref{eq:LSadd} are mis-specified.


Estimation based on specification W uses the $T-1$ moment conditions
\begin{equation}
E\left[x_{i,t-1} \left(\Delta y_{it} - \theta \Delta x_{it}\right)\right] = 0, \mbox{ for } t = 2, \hdots, T
\end{equation}
to which specification S adds a further $T-1$ moment conditions, namely
\begin{equation}
\label{eq:Sadd}
E\left[x_{it} \left(\Delta y_{it} - \theta \Delta x_{it}\right)\right] = 0, \mbox{ for } t = 2, \hdots, T
\end{equation}
for a total of $2(T - 1)$ conditions. Because specifications W and S use the wrong model, however, these moment conditions are mis-specified:
\begin{equation}
\label{eq:trueexpect}
E\left[\left(\begin{array}{c}x_{i,t-1}\\x_{it}\end{array}\right) \left(\Delta y_{it} - \theta \Delta x_{it}\right)\right] = \left[\begin{array}{c}\gamma E[x_{it-1}\Delta y_{it-1}]\\\gamma E[x_{it}\Delta y_{it-1}] - \sigma_{xv}\end{array} \right]
\end{equation}
which are non-zero unless $\sigma_{xv} = \gamma = 0$.



\subsection{Estimators and Local Mis-specification}

Our aim is to use the GFIC to choose between competing estimators of $\theta$ on the basis of AMSE. 
To do so we must first specify the appropriate form of local mis-specification by analogy with Assumption \ref{assump:local}.
In this example, the parameters $\gamma$ and $\sigma_{xv}$ control the degree of mis-specification present in LS, W and S. 
When $\gamma=0$, both models, with and without a lag, are correctly specified; when $\sigma_{xv}=0$ all instruments under consideration are valid. 
Accordingly, we let $\gamma = \delta/\sqrt{n}$ and $-\sigma_{xv} = \tau/\sqrt{n}$ so that, in the limit, all four specifications are correct. 
In this framework the true parameter vector is $\beta_n = \left(\delta/\sqrt{n}, \theta_0\right)'$ which converges to $\beta_0 = \left(0,\theta_0\right)'$. 

\begin{assump}[Local Mis-specification for Dynamic Panel Example]
\label{assump:localex}
Assume that $\gamma = \delta/\sqrt{n}$ and $-\sigma_{xv} = \tau/\sqrt{n}$ where $\delta$ and $\tau$ are unknown constants.
\end{assump}

To define the estimators corresponding to specifications LW, LS, W and S we first require some additional notation. The symbol ``+'' used as a superscript indicates the inclusion of the extra time period $t=2$ that becomes available when we exclude the lagged dependent variable.
Using this convention, let $\Delta y_i = \left( \Delta y_{i3}, \hdots, \Delta y_{iT} \right)'$ and  $\Delta y_i^+ = \left( \Delta y_{i2},  \hdots, \Delta y_{iT} \right)'$.
Define $\Delta x_i, \Delta x_i^+$ and $\Delta v_i, \Delta v_i^+$ analogously. 
Similarly, let $\Delta y_{i,-1}=\left(\Delta y_{i2}, \hdots, \Delta y_{i,T-1}\right)'$ and $\Delta y_{i,-1}^+=\left(\Delta y_{i1}, \hdots, \Delta y_{i,T-1}\right)'$.
Note that the first element of $\Delta y_{i,-1}^+$ is not observed as $t=1$ is the first available time period. 
Stacking over individuals in the usual way, define $\Delta y = \left( \Delta y_1', \hdots, \Delta y_n'\right)'$  and so on.

The specifications LW and LS share the same model, and hence a design matrix. We denote this as:
	\begin{equation}
	X_L = \left[\begin{array}{cc}  \Delta y_{-1} & \Delta x \end{array}\right]
	\end{equation}
where the subscript $L$ indicates that both of these specifications include a lagged dependent variable.
Similarly, let
\begin{equation}
	X_L^+ = \left[ \begin{array}{cc}\Delta y_{-1}^+ & \Delta x^+ \end{array} \right].
\end{equation}
Although $X_L^+$ is not observed, we use it in the derivations that follow as it allows us to represent the true data generating process in matrix form.
Specifically, 
	\begin{eqnarray}
	\label{eq:DGP}
		\Delta y &=& X_L \beta_n + \Delta v\\
		\label{eq:DGPplus}
		\Delta y^+ &=& X_L^+ \beta_n + \Delta v^+
	\end{eqnarray}

We now turn our attention to the instrument matrices. For ease of notation, define the $(T-k+1)\times 1$ column vector
	\begin{equation}
		\left\{ z_t\right\}_{t=k}^{T} = \left(z_k, z_{k+1}, \hdots, z_{T-1}, z_T \right)'
	\end{equation}
and the $(T-k+1)\times (T-k+1)$ diagonal matrix
\begin{equation}
		D\left\{ z_t \right\}_{t=k}^{T} = \left[\begin{array}{ccc} z_{k} & & 0\\ &\ddots&\\ 0 &&z_T \end{array}\right].
\end{equation}
To construct the instrument matrices, first define the $(T-2)\times(T-2)$ submatrices
\begin{eqnarray}
	Z(y_{i,-2}) &=& D\left\{ y_{i,t-2} \right\}_{t=3}^{T}\\
	Z(x_{i,-1}) &=& D\left\{ x_{i,t-1} \right\}_{t=3}^{T}\\
	\label{eq:Zx}
		Z(x_i) &=& D\left\{x_{it}  \right\}_{t=3}^{T}
 \end{eqnarray}
and the $(T-1)\times(T-1)$ submatrices
\begin{eqnarray}
	Z(x_{i,-1}^+) &=&D\left\{ x_{i,t-1} \right\}_{t=2}^{T}\\
		Z(x_i^+) &=& D\left\{x_{it}  \right\}_{t=2}^{T}.
 \end{eqnarray}
As above, the symbol ``+'' used as a superscript indicates the addition of an additional time period. 
Combining these, define 
	\begin{eqnarray}
	Z_{LS,i} &=& \left(Z(y_{i,-2}), Z(x_{i,-1}), Z(x_i)  \right)'\\
	Z_{LW,i} &=&  \left(Z(y_{i,-2}), Z(x_{i,-1}) \right)'\\
	Z_{S,i} &=& \left(Z(x_{i,-1}^+), Z(x_i^+) \right)'\\
	Z_{W,i} &=& Z(x_{i,-1}^+).
	\end{eqnarray}
Stacking over individuals, let $Z_{LS}' = \left(Z_{LS,1}, \hdots,  Z_{LS,N}\right)$ and so on. 
Finally, define the shorthand
\begin{equation}
\label{eq:K}
	\widehat{K} = \left[\left(\frac{X'Z}{n}\right)\left(\frac{Z'Z}{n}\right)^{-1}\left(\frac{Z'X}{n}\right)\right]^{-1}\left(\frac{X'Z}{n}\right)\left(\frac{Z'Z}{n}\right)^{-1}.
\end{equation}
Using this notation, our four estimators are:
\begin{eqnarray}
	\widehat{\beta}_{LS} &=&  \widehat{K}_{LS}\left(\frac{Z_{LS}'\Delta y}{n}\right)\\
	\widehat{\beta}_{LW} &=& \widehat{K}_{LW}\left(\frac{Z_{LW}'\Delta y}{n}\right)\\
	\widehat{\theta}_{S} &=&  \widehat{K}_S\left(\frac{Z_{S}'\Delta y^+}{n}\right)\\
	\widehat{\theta}_{W} &=&  \widehat{K}_W\left(\frac{Z_{W}'\Delta y^+}{n}\right).
\end{eqnarray}
which can be expanded as 
	\begin{eqnarray}
	\label{eq:distexpandLS}
		\sqrt{n}(\widehat{\beta}_{LS} - \beta_0) = \sqrt{n} \left[\begin{array}{l} \widehat{\gamma}_{LS}\\ \widehat{\theta}_{LS} - \theta_0\end{array}\right]   &=& \left[\begin{array}{c}\delta\\ 0\end{array}\right]+ \widehat{K}_{LS}\left(\frac{Z_{LS}'\Delta v}{n^{1/2}}\right)\\
						\sqrt{n}(\widehat{\beta}_{LW} - \beta_0) = \sqrt{n} \left[\begin{array}{l} \widehat{\gamma}_{LW}\\ \widehat{\theta}_{LW} - \theta_0\end{array}\right]   &=& \left[\begin{array}{c}\delta\\ 0\end{array}\right]+ \widehat{K}_{LW}\left(\frac{Z_{LW}'\Delta v}{n^{1/2}}\right)
\end{eqnarray}
and
\begin{eqnarray}
		\sqrt{n}\left(\widehat{\theta}_S -\theta_0\right)&=& \widehat{K}_S\left[\delta\left( \frac{Z_{S}'\Delta y_{-1}^+}{n}\right) + \left( \frac{Z_{S}'\Delta v^+}{n^{1/2}}\right)\right]\\
		\label{eq:distexpandW}
		\sqrt{n}\left(\widehat{\theta}_W-\theta_0\right) &=&  \widehat{K}_W\left[\delta\left( \frac{Z_{W}'\Delta y_{-1}^+}{n}\right) + \left( \frac{Z_{W}'\Delta v^+}{n^{1/2}}\right)\right]
	\end{eqnarray}
by substituting Equation \ref{eq:DGP}. Combining these expressions with the Lindeberg-Feller central limit theorem and standard regularity conditions gives
	\begin{eqnarray}
		\label{eq:dynpan1}
			\sqrt{n} \left[\begin{array}{l} \widehat{\gamma}_{LS}\\ \widehat{\theta}_{LS} - \theta_0\end{array}\right]   &\overset{d}{\rightarrow}& \left[\begin{array}{c}\delta\\ 0\end{array}\right] +K_{LS} \left\{ \left[\begin{array}{c}0_2\\ \tau \end{array}\right]\otimes \iota_{T-2} + N\left(0, \mathcal{V}_{LS}\right)\right\}\\
			\label{eq:dynpan2}
 			\sqrt{n} \left[\begin{array}{l} \widehat{\gamma}_{LW}\\ \widehat{\theta}_{LW} - \theta_0\end{array}\right]   &\overset{d}{\rightarrow}& \left[\begin{array}{c}\delta\\ 0\end{array}\right] +K_{LW}\; N\left(0, \mathcal{V}_{LW}\right)
	\end{eqnarray}
and
\begin{eqnarray}
\label{eq:dynpan3}
 	\sqrt{n}\left(\widehat{\theta}_{S}-\theta_0\right) &\overset{d}{\rightarrow}&K_S \left[\left(\delta \left[\begin{array}{l} \psi_0\\ \psi_1\end{array} \right] + \left[\begin{array}{c}0\\ \tau \end{array}\right]\right)\otimes \iota_{T-1}+ N\left(0, \mathcal{V}_{S}\right)\right]\\
 	\label{eq:dynpan4}	\sqrt{n}\left(\widehat{\theta}_{W}-\theta_0\right)&\overset{d}{\rightarrow}&K_W  \left[\delta \psi_0 \otimes \iota_{T-1} + N\left(0, \mathcal{V}_W\right) \right].
	\end{eqnarray}
where $K$ denotes the probability limit of $\widehat{K}$ (see Equation \ref{eq:K}) and
	\begin{eqnarray}
		\psi_0 &=&E[x_{it}\Delta y_{it}] \\
		\psi_1 &=&E[x_{it} \Delta y_{it-1}]
	\end{eqnarray}	
with the expectations taken with respect to the limiting DGP, in which all four specifications are correct. 
These expressions immediately yield the AMSE of each estimator of $\theta$. 
To implement the GFIC, we simply estimate the unknowns, as described below.

\subsection{GFIC for the Dynamic Panel Example}
To operationalize the GFIC, we need estimates of the unknowns in Equations \ref{eq:dynpan1}--\ref{eq:dynpan4}.
To estimate $K_{LS}$, $K_{LW}$, $K_W$ and $K_S$ we use $\widehat{K}_{LS}$, $\widehat{K}_{LW}$, $\widehat{K}_W$ and $\widehat{K}_S$, which remain consistent under local mis-specification. 
There are many consistent estimators of the variance matrices $\mathcal{V}_{LS}$, $\mathcal{V}_{LW}$, $\mathcal{V}_{S}$ and $\mathcal{V}_{W}$ under local mis-specification. 
For robustness, we use the centered, panel robust estimator that allows for heteroscedasticity. 
We do not center the estimator for LW because this specification is assumed correct, and this yields a more efficient estimator. 
Using the assumption of stationarity, 
	\begin{eqnarray*}
		\widehat{\psi}_0 &=&\frac{1}{n(T-1)} \sum_{t=2}^T\sum_{i=1}^N x_{it} \Delta y_{it}\\
		\widehat{\psi}_1 &=&\frac{1}{n(T-2)} \sum_{t=3}^T\sum_{i=1}^N x_{it} \Delta y_{it-1}
	\end{eqnarray*}
provide consistent estimators of $\psi_0$ and $\psi_1$.
The only remaining quantities needed to calculate the GFIC involve the bias parameters $\tau$ and $\delta$.
As described above, no consistent estimators of these quantities exist under local mis-specification.
It remains possible, however, to construct asymptotically unbiased estimators.
We can read off an asymptotically unbiased estimator of $\delta$ directly from Equation \ref{eq:dynpan2}, namely $\widehat{\delta} = \sqrt{n}\; \widehat{\gamma}_{LW}$.
To construct an asymptotically unbiased estimator of $\tau$, we define $Z'(x) = \left(Z(x_1), \hdots, Z(x_n)\right)$, see Equation \ref{eq:Zx}, and expand the quantity $n^{-1/2}(\Delta y -X_L\widehat{\beta}_{LW})$ as follows:
$$n^{-1/2}(\Delta y -X_L\widehat{\beta}_{LW}) = \left[\begin{array}{cc} -n^{-1} Z'(x)X_L \widehat{K}_{LW}& I \end{array} \right]n^{-1/2} Z'_{LS}\Delta v$$
Now, by the Lindeberg-Feller Central Limit Theorem (c.f.\ Equation \ref{eq:dynpan1}) we have
$$n^{-1/2} Z'_{LS}\Delta v \overset{d}{\rightarrow}\left[\begin{array}{c}0_2\\ \tau \end{array}\right]\otimes \iota_{T-2} + N\left(0, \mathcal{V}_{LS}\right)$$
and by a Law of Large Numbers,
	$$n^{-1}Z'(x)X_L \overset{p}{\rightarrow} E\left[\begin{array}{cc} x_{it}\Delta y_{it-1} & x_{it}\Delta x_{it}\end{array} \right]\otimes \iota_{T-2}$$
where the expectations are taken with respect to the limiting DGP. 
Thus,
	\begin{equation}
		n^{-1/2}(\Delta y -X_L\widehat{\beta}_{LW}) \overset{d}{\rightarrow} \tau \otimes \iota_{T-2} + \left[ \begin{array}{cc} \Psi & I\end{array}\right] N(0, \mathcal{V}_{LS})
	\end{equation}
where
\begin{equation}
	\Psi = -E\left[\begin{array}{cc} x_{it}\Delta y_{it-1} & x_{it}\Delta x_{it}\end{array} \right]\otimes \iota_{T-2} K_{LW}
\end{equation}
Using stationarity to gain efficiency we take the time average
\begin{equation}
\widetilde{\tau} =  \left(\frac{\iota'_{T-2}}{T-2} \right)n^{-1/2} Z'(x)(\Delta y - X_L \widehat{\beta}_{LW})
\end{equation}
as our estimator of $\tau$. 
It follows from above that
\begin{equation}
	\widetilde{\tau} \overset{d}{\rightarrow} \tau + \left(\frac{\iota'_{T-2}}{T-2} \right)\left[ \begin{array}{cc} \Psi & I\end{array}\right] N(0, \mathcal{V}_{LS})
\end{equation}
As describe above for the general GMM case, asymptotically unbiased estimators of $\tau$ and $\delta$ require a bias correction to provide asymptotically unbiased estimators of the quantities $\tau^2$, $\delta^2$ and $\tau\delta$ needed to estimate AMSE. 
To carry out this correction, we use the joint distribution of the bias parameter estimators:
	\begin{equation}
	 \left[\begin{array}{c} \widehat{\delta} \\ \widetilde{\tau}  \end{array} \right] \overset{d}{\rightarrow} \left[\begin{array}{c} \widehat{\delta} \\ \widetilde{\tau}  \end{array} \right]  + \left[\begin{array}{cc} K_{LW}^\gamma&0 \\ \left(\frac{\iota'_{T-2}}{T-2} \right) \Psi&  \left(\frac{\iota'_{T-2}}{T-2} \right) I\end{array} \right] N(0, \mathcal{V}_{LS})
	\end{equation}
where $K_{LW}^\gamma$ denotes the first row of $K_{LW}$ (i.e.\ the row corresponding to $\gamma$).
Asymptotically unbiased estimators of $\delta^2$, $\tau^2$ and $\tau\delta$ are given by
\begin{eqnarray}
	\delta^2 \colon &&\widehat{\delta}^2 - \widehat{\sigma}_\delta^2\\
	\tau^2 \colon &&\widetilde{\tau}^2 - \widehat{\sigma}_\tau^2\\
	\tau \delta \colon && \widetilde{\tau}\widehat{\delta} - \widehat{\sigma}_{\tau\delta}
\end{eqnarray}
where $\widehat{\sigma}_\delta^2$, $\widehat{\sigma}_\tau^2$ and $\widehat{\sigma}_{\tau\delta}$ are consistent estimators of the elements of
$$\left[\begin{array}{cc} K_{LW}^\gamma&0 \\ \left(\frac{\iota'_{T-2}}{T-2} \right) \Psi&  \left(\frac{\iota'_{T-2}}{T-2} \right) I\end{array} \right] \mathcal{V}_{LS}  \left[\begin{array}{cc} K_{LW}^\gamma&0 \\ \left(\frac{\iota'_{T-2}}{T-2} \right) \Psi&  \left(\frac{\iota'_{T-2}}{T-2} \right) I\end{array} \right]'$$
We have already described how to consistently estimate $K_{LW}$ and $\mathcal{V}_{LS}$ above, so the only quantities for which we still require consistent estimators are 
	\begin{eqnarray}
		\omega_1 &=& E[x_{it}\Delta y_{it-1}]\\
		 \omega_2 &=& E[x_{it}\Delta x_{it}]
	\end{eqnarray}
which appear in the expression for $\Psi$.
Under stationarity, the following estimators are consistent:
		\begin{eqnarray}
		\widehat{\omega}_1 &=& \frac{1}{n(T-2)}\sum_{t=3}^T \sum_{i=1}^n x_{it}\Delta y_{it-1}\\
		 \widehat{\omega}_2 &=&\frac{1}{n(T-1)}\sum_{t=2}^T \sum_{i=1}^n x_{it}\Delta x_{it}
	\end{eqnarray}
Substituting these estimators into the AMSE expressions implied by Equations \ref{eq:dynpan1}--\ref{eq:dynpan4} yields the GFIC.
	

